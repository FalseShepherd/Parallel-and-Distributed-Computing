

Container: container_1464147437282_0417_01_000002 on parcom02.cs.du.edu_36606
===============================================================================
LogType:stderr
Log Upload Time:27-May-2016 19:33:42
LogLength:911
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/giraph-1.1.0/giraph-core/target/giraph-1.1.0-for-hadoop-2.6.0-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/giraph-1.1.0/giraph-examples/target/giraph-examples-1.1.0-for-hadoop-2.6.0-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

LogType:stdout
Log Upload Time:27-May-2016 19:33:42
LogLength:0
Log Contents:

LogType:syslog
Log Upload Time:27-May-2016 19:33:42
LogLength:63582
Log Contents:
2016-05-27 19:33:14,737 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-05-27 19:33:14,932 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-05-27 19:33:15,022 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-05-27 19:33:15,022 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2016-05-27 19:33:15,036 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2016-05-27 19:33:15,036 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1464147437282_0417, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@604752dd)
2016-05-27 19:33:15,216 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2016-05-27 19:33:15,613 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417
2016-05-27 19:33:16,214 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-05-27 19:33:17,019 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-05-27 19:33:17,297 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2016-05-27 19:33:17,360 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
2016-05-27 19:33:17,420 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-05-27 19:33:17,420 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-05-27 19:33:17,421 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: job.local.dir is deprecated. Instead, use mapreduce.job.local.dir
2016-05-27 19:33:17,432 INFO [main] org.apache.giraph.zk.ZooKeeperManager: createCandidateStamp: Made the directory _bsp/_defaultZkManagerDir/job_1464147437282_0417
2016-05-27 19:33:17,434 INFO [main] org.apache.giraph.zk.ZooKeeperManager: createCandidateStamp: Made the directory _bsp/_defaultZkManagerDir/job_1464147437282_0417/_zkServer
2016-05-27 19:33:17,447 INFO [main] org.apache.giraph.zk.ZooKeeperManager: createCandidateStamp: Creating my filestamp _bsp/_defaultZkManagerDir/job_1464147437282_0417/_task/parcom02.cs.du.edu 0
2016-05-27 19:33:17,510 INFO [main] org.apache.giraph.zk.ZooKeeperManager: getZooKeeperServerList: Got [parcom01.cs.du.edu, parcom02.cs.du.edu, parcom03.cs.du.edu, parcom04.cs.du.edu] 4 hosts from 4 candidates when 1 required (polling period is 3000) on attempt 0
2016-05-27 19:33:17,510 INFO [main] org.apache.giraph.zk.ZooKeeperManager: createZooKeeperServerList: Creating the final ZooKeeper file '_bsp/_defaultZkManagerDir/job_1464147437282_0417/zkServerList_parcom01.cs.du.edu 2 '
2016-05-27 19:33:17,518 INFO [main] org.apache.giraph.zk.ZooKeeperManager: getZooKeeperServerList: For task 0, got file 'zkServerList_parcom01.cs.du.edu 2 ' (polling period is 3000)
2016-05-27 19:33:17,518 INFO [main] org.apache.giraph.zk.ZooKeeperManager: getZooKeeperServerList: Found [parcom01.cs.du.edu, 2] 2 hosts in filename 'zkServerList_parcom01.cs.du.edu 2 '
2016-05-27 19:33:17,526 INFO [main] org.apache.giraph.zk.ZooKeeperManager: onlineZooKeeperSErvers: Empty directory _bsp/_defaultZkManagerDir/job_1464147437282_0417/_zkServer, waiting 3000 msecs.
2016-05-27 19:33:20,529 INFO [main] org.apache.giraph.zk.ZooKeeperManager: onlineZooKeeperSErvers: Empty directory _bsp/_defaultZkManagerDir/job_1464147437282_0417/_zkServer, waiting 3000 msecs.
2016-05-27 19:33:23,532 INFO [main] org.apache.giraph.zk.ZooKeeperManager: onlineZooKeeperServers: Got [parcom01.cs.du.edu] 1 hosts from 1 ready servers when 1 required (polling period is 3000) on attempt 2
2016-05-27 19:33:23,538 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Starting up BspServiceMaster (master thread)...
2016-05-27 19:33:23,577 INFO [main] org.apache.giraph.bsp.BspService: BspService: Path to create to halt is /_hadoopBsp/job_1464147437282_0417/_haltComputation
2016-05-27 19:33:23,577 INFO [main] org.apache.giraph.bsp.BspService: BspService: Connecting to ZooKeeper with job job_1464147437282_0417, 0 on parcom01.cs.du.edu:22181
2016-05-27 19:33:23,592 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
2016-05-27 19:33:23,592 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:host.name=parcom02.cs.du.edu
2016-05-27 19:33:23,592 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:java.version=1.7.0_95
2016-05-27 19:33:23,593 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2016-05-27 19:33:23,593 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
2016-05-27 19:33:23,593 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:java.class.path=/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000002:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000002/AllShortestPaths.jar:/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000002/giraph-1.1.0-for-hadoop-2.6.0.jar:/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000002/job.jar:/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000002/conf:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/giraph-1.1.0-for-hadoop-2.6.0-jar-with-dependencies.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/giraph-examples-1.1.0-for-hadoop-2.6.0-jar-with-dependencies.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar
2016-05-27 19:33:23,593 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:java.library.path=/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000002:/usr/local/hadoop-2.6.0/lib/native:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2016-05-27 19:33:23,593 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000002/tmp
2016-05-27 19:33:23,593 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2016-05-27 19:33:23,593 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:os.name=Linux
2016-05-27 19:33:23,593 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:os.arch=amd64
2016-05-27 19:33:23,593 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:os.version=3.2.0-4-amd64
2016-05-27 19:33:23,593 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:user.name=hduser
2016-05-27 19:33:23,593 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:user.home=/home/hduser
2016-05-27 19:33:23,593 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:user.dir=/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000002
2016-05-27 19:33:23,595 INFO [main] org.apache.zookeeper.ZooKeeper: Initiating client connection, connectString=parcom01.cs.du.edu:22181 sessionTimeout=60000 watcher=org.apache.giraph.master.BspServiceMaster@426c958c
2016-05-27 19:33:23,630 INFO [main-SendThread(parcom01.cs.du.edu:22181)] org.apache.zookeeper.ClientCnxn: Opening socket connection to server parcom01.cs.du.edu/130.253.8.34:22181. Will not attempt to authenticate using SASL (unknown error)
2016-05-27 19:33:23,631 INFO [main-SendThread(parcom01.cs.du.edu:22181)] org.apache.zookeeper.ClientCnxn: Socket connection established to parcom01.cs.du.edu/130.253.8.34:22181, initiating session
2016-05-27 19:33:23,640 INFO [main-SendThread(parcom01.cs.du.edu:22181)] org.apache.zookeeper.ClientCnxn: Session establishment complete on server parcom01.cs.du.edu/130.253.8.34:22181, sessionid = 0x154f4fe78fa0002, negotiated timeout = 600000
2016-05-27 19:33:23,643 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: Asynchronous connection complete.
2016-05-27 19:33:23,671 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Starting up BspServiceWorker...
2016-05-27 19:33:23,681 INFO [main] org.apache.giraph.bsp.BspService: BspService: Path to create to halt is /_hadoopBsp/job_1464147437282_0417/_haltComputation
2016-05-27 19:33:23,681 INFO [main] org.apache.giraph.bsp.BspService: BspService: Connecting to ZooKeeper with job job_1464147437282_0417, 0 on parcom01.cs.du.edu:22181
2016-05-27 19:33:23,681 INFO [main] org.apache.zookeeper.ZooKeeper: Initiating client connection, connectString=parcom01.cs.du.edu:22181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@5d273e13
2016-05-27 19:33:23,684 INFO [main-SendThread(parcom01.cs.du.edu:22181)] org.apache.zookeeper.ClientCnxn: Opening socket connection to server parcom01.cs.du.edu/130.253.8.34:22181. Will not attempt to authenticate using SASL (unknown error)
2016-05-27 19:33:23,689 INFO [main-SendThread(parcom01.cs.du.edu:22181)] org.apache.zookeeper.ClientCnxn: Socket connection established to parcom01.cs.du.edu/130.253.8.34:22181, initiating session
2016-05-27 19:33:23,691 INFO [main-SendThread(parcom01.cs.du.edu:22181)] org.apache.zookeeper.ClientCnxn: Session establishment complete on server parcom01.cs.du.edu/130.253.8.34:22181, sessionid = 0x154f4fe78fa0003, negotiated timeout = 600000
2016-05-27 19:33:23,691 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: Asynchronous connection complete.
2016-05-27 19:33:23,717 INFO [org.apache.giraph.master.MasterThread] org.apache.giraph.bsp.BspService: getJobState: Job state already exists (/_hadoopBsp/job_1464147437282_0417/_masterJobState)
2016-05-27 19:33:23,731 INFO [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster: becomeMaster: First child is '/_hadoopBsp/job_1464147437282_0417/_masterElectionDir/parcom01.cs.du.edu_20000000000' and my bid is '/_hadoopBsp/job_1464147437282_0417/_masterElectionDir/parcom02.cs.du.edu_00000000001'
2016-05-27 19:33:23,731 INFO [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster: becomeMaster: Waiting to become the master...
2016-05-27 19:33:23,835 INFO [main] org.apache.giraph.comm.netty.NettyServer: NettyServer: Using execution group with 8 threads for requestFrameDecoder.
2016-05-27 19:33:23,872 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2016-05-27 19:33:23,893 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: masterElectionChildrenChanged signaled
2016-05-27 19:33:23,895 INFO [org.apache.giraph.master.MasterThread] org.apache.giraph.bsp.BspService: getJobState: Job state already exists (/_hadoopBsp/job_1464147437282_0417/_masterJobState)
2016-05-27 19:33:23,897 INFO [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster: becomeMaster: First child is '/_hadoopBsp/job_1464147437282_0417/_masterElectionDir/parcom01.cs.du.edu_20000000000' and my bid is '/_hadoopBsp/job_1464147437282_0417/_masterElectionDir/parcom02.cs.du.edu_00000000001'
2016-05-27 19:33:23,897 INFO [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster: becomeMaster: Waiting to become the master...
2016-05-27 19:33:23,952 WARN [main] org.apache.giraph.comm.netty.NettyServer: start: Likely failed to bind on attempt 0 to port 30000
2016-05-27 19:33:23,956 WARN [main] org.apache.giraph.comm.netty.NettyServer: start: Likely failed to bind on attempt 1 to port 30010
2016-05-27 19:33:23,967 INFO [main] org.apache.giraph.comm.netty.NettyServer: start: Started server communication server: parcom02.cs.du.edu/130.253.8.35:30020 with up to 16 threads on bind attempt 2 with sendBufferSize = 32768 receiveBufferSize = 524288
2016-05-27 19:33:23,979 INFO [main] org.apache.giraph.comm.netty.NettyClient: NettyClient: Using execution handler with 8 threads after request-encoder.
2016-05-27 19:33:24,002 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Registering health of this worker...
2016-05-27 19:33:24,013 INFO [main] org.apache.giraph.bsp.BspService: getJobState: Job state already exists (/_hadoopBsp/job_1464147437282_0417/_masterJobState)
2016-05-27 19:33:24,016 INFO [main] org.apache.giraph.bsp.BspService: getApplicationAttempt: Node /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir already exists!
2016-05-27 19:33:24,018 INFO [main] org.apache.giraph.bsp.BspService: getApplicationAttempt: Node /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir already exists!
2016-05-27 19:33:24,026 INFO [main] org.apache.giraph.worker.BspServiceWorker: registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/parcom02.cs.du.edu_0 and workerInfo= Worker(hostname=parcom02.cs.du.edu, MRtaskID=0, port=30020)
2016-05-27 19:33:24,078 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: masterElectionChildrenChanged signaled
2016-05-27 19:33:24,080 INFO [org.apache.giraph.master.MasterThread] org.apache.giraph.bsp.BspService: getJobState: Job state already exists (/_hadoopBsp/job_1464147437282_0417/_masterJobState)
2016-05-27 19:33:24,083 INFO [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster: becomeMaster: First child is '/_hadoopBsp/job_1464147437282_0417/_masterElectionDir/parcom01.cs.du.edu_20000000000' and my bid is '/_hadoopBsp/job_1464147437282_0417/_masterElectionDir/parcom02.cs.du.edu_00000000001'
2016-05-27 19:33:24,083 INFO [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster: becomeMaster: Waiting to become the master...
2016-05-27 19:33:24,297 INFO [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer: start: Using Netty without authentication.
2016-05-27 19:33:24,306 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: partitionAssignmentsReadyChanged (partitions are assigned)
2016-05-27 19:33:24,319 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Master(hostname=parcom01.cs.du.edu, MRtaskID=2, port=30002)
2016-05-27 19:33:24,319 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Ready for computation on superstep -1 since worker selection and vertex range assignments are done in /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/-1/_addressesAndPartitions
2016-05-27 19:33:24,323 INFO [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer: start: Using Netty without authentication.
2016-05-27 19:33:24,333 INFO [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer: start: Using Netty without authentication.
2016-05-27 19:33:24,332 INFO [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient: Using Netty without authentication.
2016-05-27 19:33:24,333 INFO [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient: Using Netty without authentication.
2016-05-27 19:33:24,334 INFO [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient: Using Netty without authentication.
2016-05-27 19:33:24,340 INFO [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient: Using Netty without authentication.
2016-05-27 19:33:24,348 INFO [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer: start: Using Netty without authentication.
2016-05-27 19:33:24,366 INFO [main] org.apache.giraph.comm.netty.NettyClient: connectAllAddresses: Successfully added 4 connections, (4 total connected) 0 failed, 0 failures total.
2016-05-27 19:33:24,371 INFO [netty-server-worker-2] org.apache.giraph.comm.netty.handler.RequestDecoder: decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0003, ave received req MBytes = 0.0001, secs waited = 1.4643991E9
2016-05-27 19:33:24,418 INFO [main] org.apache.giraph.worker.BspServiceWorker: loadInputSplits: Using 1 thread(s), originally 1 threads(s) for 4 total splits.
2016-05-27 19:33:24,438 INFO [load-0] org.apache.giraph.worker.InputSplitsHandler: reserveInputSplit: Reserved input split path /_hadoopBsp/job_1464147437282_0417/_edgeInputSplitDir/0, overall roughly 0.0% input splits reserved
2016-05-27 19:33:24,444 INFO [load-0] org.apache.giraph.worker.InputSplitsCallable: getInputSplit: Reserved /_hadoopBsp/job_1464147437282_0417/_edgeInputSplitDir/0 from ZooKeeper and got input split 'hdfs://parcom01.cs.du.edu:54410/u/home/maximkolb/Comp3705Processing/svn/Program4/Job1Output/part-r-00000:0+23807'
2016-05-27 19:33:24,446 INFO [load-0] UndirectedTextEdgeInputFormat: createEdgeReader called
2016-05-27 19:33:24,684 INFO [load-0] org.apache.giraph.worker.InputSplitsCallable: loadFromInputSplit: Finished loading /_hadoopBsp/job_1464147437282_0417/_edgeInputSplitDir/0 (v=0, e=1852)
2016-05-27 19:33:24,691 INFO [load-0] org.apache.giraph.worker.InputSplitsCallable: call: Loaded 1 input splits in 0.27213386 secs, (v=0, e=1852) 0.0 vertices/sec, 6805.4746 edges/sec
2016-05-27 19:33:24,710 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.019
MBytes/sec sent = 1.3427, MBytesSent = 0.0269, ave sent req MBytes = 0.009, secs waited = 0.019
2016-05-27 19:33:24,710 INFO [main] org.apache.giraph.worker.BspServiceWorker: setup: Finally loaded a total of (v=0, e=1852)
2016-05-27 19:33:24,719 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: edgeInputSplitsAllDoneChanged (all edges sent from input splits)
2016-05-27 19:33:24,722 INFO [main] org.apache.giraph.edge.AbstractEdgeStore: moveEdgesToVertices: Moving incoming edges to vertices.
2016-05-27 19:33:24,796 INFO [main] org.apache.giraph.edge.AbstractEdgeStore: moveEdgesToVertices: Finished moving incoming edges to vertices.
2016-05-27 19:33:24,800 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 92.91M / 145.50M / 178.00M
2016-05-27 19:33:24,801 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0003, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.11
MBytes/sec sent = 0.2419, MBytesSent = 0.0269, ave sent req MBytes = 0.009, secs waited = 0.11
2016-05-27 19:33:24,801 INFO [main] org.apache.giraph.worker.WorkerAggregatorHandler: finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
2016-05-27 19:33:24,830 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0007, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.017
MBytes/sec sent = 0.0013, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.018
2016-05-27 19:33:24,830 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 92.53M / 145.50M / 178.00M
2016-05-27 19:33:24,845 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: (waiting for rest of workers) ALL_EXCEPT_ZOOKEEPER - Attempt=0, Superstep=-1
2016-05-27 19:33:24,869 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: superstepFinished signaled
2016-05-27 19:33:24,875 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Completed superstep -1 with global stats (vtx=1000,finVtx=0,edges=7508,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=AllShortestPaths,combiner=null,incoming=null,outgoing=null)
2016-05-27 19:33:24,877 WARN [main-EventThread] org.apache.giraph.bsp.BspService: process: Unknown and unprocessed event (path=/_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
2016-05-27 19:33:24,883 INFO [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory: newStore: Created class org.apache.giraph.comm.messages.ByteArrayMessagesPerVertexStore for vertex id class org.apache.hadoop.io.Text and message value class VertexDistanceArrayWritable and no combiner
2016-05-27 19:33:24,883 INFO [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory: newStore: Created class org.apache.giraph.comm.messages.ByteArrayMessagesPerVertexStore for vertex id class org.apache.hadoop.io.Text and message value class VertexDistanceArrayWritable and no combiner
2016-05-27 19:33:24,898 INFO [main] org.apache.giraph.worker.BspServiceWorker: registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/parcom02.cs.du.edu_0 and workerInfo= Worker(hostname=parcom02.cs.du.edu, MRtaskID=0, port=30020)
2016-05-27 19:33:24,910 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: partitionAssignmentsReadyChanged (partitions are assigned)
2016-05-27 19:33:24,916 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Master(hostname=parcom01.cs.du.edu, MRtaskID=2, port=30002)
2016-05-27 19:33:24,916 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Ready for computation on superstep 0 since worker selection and vertex range assignments are done in /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/0/_addressesAndPartitions
2016-05-27 19:33:24,917 INFO [main] org.apache.giraph.comm.netty.NettyClient: connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
2016-05-27 19:33:24,918 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.106
MBytes/sec sent = 0.0002, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.106
2016-05-27 19:33:24,921 INFO [main] org.apache.giraph.worker.BspServiceWorker: sendWorkerPartitions: Done sending all my partitions.
2016-05-27 19:33:24,926 INFO [main] org.apache.giraph.worker.BspServiceWorker: exchangeVertexPartitions: Done with exchange.
2016-05-27 19:33:24,929 INFO [main] org.apache.giraph.graph.GraphTaskManager: execute: 4 partitions to process with 1 compute thread(s), originally 1 thread(s) on superstep 0
2016-05-27 19:33:25,115 INFO [compute-0] org.apache.giraph.graph.ComputeCallable: call: Computation took 0.18254207 secs for 4 partitions on superstep 0.  Flushing started
2016-05-27 19:33:25,136 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 87.21M / 145.50M / 178.00M
2016-05-27 19:33:25,137 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0018, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.021
MBytes/sec sent = 1.492, MBytesSent = 0.0328, ave sent req MBytes = 0.0109, secs waited = 0.021
2016-05-27 19:33:25,137 INFO [main] org.apache.giraph.worker.WorkerAggregatorHandler: finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
2016-05-27 19:33:25,145 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0062, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.008
MBytes/sec sent = 0.0195, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.008
2016-05-27 19:33:25,146 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Superstep 0, messages = 1863 , message bytes = 44920 , Memory (free/total/max) = 87.21M / 145.50M / 178.00M
2016-05-27 19:33:25,149 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: (waiting for rest of workers) ALL_EXCEPT_ZOOKEEPER - Attempt=0, Superstep=0
2016-05-27 19:33:25,157 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: superstepFinished signaled
2016-05-27 19:33:25,162 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Completed superstep 0 with global stats (vtx=1000,finVtx=1000,edges=7508,msgCount=7508,msgBytesCount=181024,haltComputation=false, checkpointStatus=NONE) and classes (computation=AllShortestPaths,combiner=null,incoming=null,outgoing=null)
2016-05-27 19:33:25,163 INFO [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory: newStore: Created class org.apache.giraph.comm.messages.ByteArrayMessagesPerVertexStore for vertex id class org.apache.hadoop.io.Text and message value class VertexDistanceArrayWritable and no combiner
2016-05-27 19:33:25,190 INFO [main] org.apache.giraph.worker.BspServiceWorker: registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/parcom02.cs.du.edu_0 and workerInfo= Worker(hostname=parcom02.cs.du.edu, MRtaskID=0, port=30020)
2016-05-27 19:33:25,199 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: partitionAssignmentsReadyChanged (partitions are assigned)
2016-05-27 19:33:25,204 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Master(hostname=parcom01.cs.du.edu, MRtaskID=2, port=30002)
2016-05-27 19:33:25,204 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Ready for computation on superstep 1 since worker selection and vertex range assignments are done in /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/1/_addressesAndPartitions
2016-05-27 19:33:25,204 INFO [main] org.apache.giraph.comm.netty.NettyClient: connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
2016-05-27 19:33:25,205 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0007, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.068
MBytes/sec sent = 0.0025, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.068
2016-05-27 19:33:25,208 INFO [main] org.apache.giraph.worker.BspServiceWorker: sendWorkerPartitions: Done sending all my partitions.
2016-05-27 19:33:25,209 INFO [main] org.apache.giraph.worker.BspServiceWorker: exchangeVertexPartitions: Done with exchange.
2016-05-27 19:33:25,211 INFO [main] org.apache.giraph.graph.GraphTaskManager: execute: 4 partitions to process with 1 compute thread(s), originally 1 thread(s) on superstep 1
2016-05-27 19:33:25,442 INFO [compute-0] org.apache.giraph.graph.ComputeCallable: call: Computation took 0.23006508 secs for 4 partitions on superstep 1.  Flushing started
2016-05-27 19:33:25,459 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 79.64M / 145.50M / 178.00M
2016-05-27 19:33:25,459 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0021, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.017
MBytes/sec sent = 8.554, MBytesSent = 0.154, ave sent req MBytes = 0.0513, secs waited = 0.017
2016-05-27 19:33:25,459 INFO [main] org.apache.giraph.worker.WorkerAggregatorHandler: finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
2016-05-27 19:33:25,461 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0165, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0585, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.002
2016-05-27 19:33:25,461 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Superstep 1, messages = 1863 , message bytes = 209824 , Memory (free/total/max) = 79.64M / 145.50M / 178.00M
2016-05-27 19:33:25,464 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: (waiting for rest of workers) ALL_EXCEPT_ZOOKEEPER - Attempt=0, Superstep=1
2016-05-27 19:33:25,474 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: superstepFinished signaled
2016-05-27 19:33:25,480 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Completed superstep 1 with global stats (vtx=1000,finVtx=1000,edges=7508,msgCount=7508,msgBytesCount=861712,haltComputation=false, checkpointStatus=NONE) and classes (computation=AllShortestPaths,combiner=null,incoming=null,outgoing=null)
2016-05-27 19:33:25,480 INFO [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory: newStore: Created class org.apache.giraph.comm.messages.ByteArrayMessagesPerVertexStore for vertex id class org.apache.hadoop.io.Text and message value class VertexDistanceArrayWritable and no combiner
2016-05-27 19:33:25,505 WARN [main-EventThread] org.apache.giraph.bsp.BspService: process: Unknown and unprocessed event (path=/_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/0/_addressesAndPartitions, type=NodeDeleted, state=SyncConnected)
2016-05-27 19:33:25,508 INFO [main-EventThread] org.apache.giraph.worker.BspServiceWorker: processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
2016-05-27 19:33:25,509 INFO [main] org.apache.giraph.worker.BspServiceWorker: registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/parcom02.cs.du.edu_0 and workerInfo= Worker(hostname=parcom02.cs.du.edu, MRtaskID=0, port=30020)
2016-05-27 19:33:25,512 WARN [main-EventThread] org.apache.giraph.bsp.BspService: process: Unknown and unprocessed event (path=/_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
2016-05-27 19:33:25,529 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: partitionAssignmentsReadyChanged (partitions are assigned)
2016-05-27 19:33:25,537 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Master(hostname=parcom01.cs.du.edu, MRtaskID=2, port=30002)
2016-05-27 19:33:25,538 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Ready for computation on superstep 2 since worker selection and vertex range assignments are done in /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/2/_addressesAndPartitions
2016-05-27 19:33:25,538 INFO [main] org.apache.giraph.comm.netty.NettyClient: connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
2016-05-27 19:33:25,538 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0006, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.079
MBytes/sec sent = 0.0022, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.079
2016-05-27 19:33:25,541 INFO [main] org.apache.giraph.worker.BspServiceWorker: sendWorkerPartitions: Done sending all my partitions.
2016-05-27 19:33:25,543 INFO [main] org.apache.giraph.worker.BspServiceWorker: exchangeVertexPartitions: Done with exchange.
2016-05-27 19:33:25,545 INFO [main] org.apache.giraph.graph.GraphTaskManager: execute: 4 partitions to process with 1 compute thread(s), originally 1 thread(s) on superstep 2
2016-05-27 19:33:25,777 INFO [compute-0] org.apache.giraph.graph.ComputeCallable: call: Computation took 0.23213655 secs for 4 partitions on superstep 2.  Flushing started
2016-05-27 19:33:25,814 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 113.95M / 137.00M / 178.00M
2016-05-27 19:33:25,830 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0007, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.053
MBytes/sec sent = 23.1222, MBytesSent = 1.2486, ave sent req MBytes = 0.4162, secs waited = 0.053
2016-05-27 19:33:25,830 INFO [main] org.apache.giraph.worker.WorkerAggregatorHandler: finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
2016-05-27 19:33:25,832 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0165, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0585, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.002
2016-05-27 19:33:25,832 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Superstep 2, messages = 1863 , message bytes = 1694944 , Memory (free/total/max) = 113.04M / 137.00M / 178.00M
2016-05-27 19:33:25,834 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: (waiting for rest of workers) ALL_EXCEPT_ZOOKEEPER - Attempt=0, Superstep=2
2016-05-27 19:33:25,845 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: superstepFinished signaled
2016-05-27 19:33:25,847 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Completed superstep 2 with global stats (vtx=1000,finVtx=1000,edges=7508,msgCount=7508,msgBytesCount=7067968,haltComputation=false, checkpointStatus=NONE) and classes (computation=AllShortestPaths,combiner=null,incoming=null,outgoing=null)
2016-05-27 19:33:25,848 INFO [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory: newStore: Created class org.apache.giraph.comm.messages.ByteArrayMessagesPerVertexStore for vertex id class org.apache.hadoop.io.Text and message value class VertexDistanceArrayWritable and no combiner
2016-05-27 19:33:25,864 WARN [main-EventThread] org.apache.giraph.bsp.BspService: process: Unknown and unprocessed event (path=/_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/1/_addressesAndPartitions, type=NodeDeleted, state=SyncConnected)
2016-05-27 19:33:25,865 INFO [main] org.apache.giraph.worker.BspServiceWorker: registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/parcom02.cs.du.edu_0 and workerInfo= Worker(hostname=parcom02.cs.du.edu, MRtaskID=0, port=30020)
2016-05-27 19:33:25,866 INFO [main-EventThread] org.apache.giraph.worker.BspServiceWorker: processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
2016-05-27 19:33:25,870 WARN [main-EventThread] org.apache.giraph.bsp.BspService: process: Unknown and unprocessed event (path=/_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
2016-05-27 19:33:25,885 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: partitionAssignmentsReadyChanged (partitions are assigned)
2016-05-27 19:33:25,890 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Master(hostname=parcom01.cs.du.edu, MRtaskID=2, port=30002)
2016-05-27 19:33:25,890 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Ready for computation on superstep 3 since worker selection and vertex range assignments are done in /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/3/_addressesAndPartitions
2016-05-27 19:33:25,890 INFO [main] org.apache.giraph.comm.netty.NettyClient: connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
2016-05-27 19:33:25,893 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0008, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.062
MBytes/sec sent = 0.0028, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.063
2016-05-27 19:33:25,895 INFO [main] org.apache.giraph.worker.BspServiceWorker: sendWorkerPartitions: Done sending all my partitions.
2016-05-27 19:33:25,897 INFO [main] org.apache.giraph.worker.BspServiceWorker: exchangeVertexPartitions: Done with exchange.
2016-05-27 19:33:25,898 INFO [main] org.apache.giraph.graph.GraphTaskManager: execute: 4 partitions to process with 1 compute thread(s), originally 1 thread(s) on superstep 3
2016-05-27 19:33:26,589 INFO [compute-0] org.apache.giraph.graph.ComputeCallable: call: Computation took 0.6896504 secs for 4 partitions on superstep 3.  Flushing started
2016-05-27 19:33:26,602 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 42.89M / 136.50M / 178.00M
2016-05-27 19:33:26,609 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0021, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.03
MBytes/sec sent = 47.0812, MBytesSent = 1.4595, ave sent req MBytes = 0.2919, secs waited = 0.03
2016-05-27 19:33:26,609 INFO [main] org.apache.giraph.worker.WorkerAggregatorHandler: finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
2016-05-27 19:33:26,612 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0124, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.0439, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.003
2016-05-27 19:33:26,613 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Superstep 3, messages = 1863 , message bytes = 15683801 , Memory (free/total/max) = 42.71M / 136.50M / 178.00M
2016-05-27 19:33:26,616 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: (waiting for rest of workers) ALL_EXCEPT_ZOOKEEPER - Attempt=0, Superstep=3
2016-05-27 19:33:26,625 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: superstepFinished signaled
2016-05-27 19:33:26,632 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Completed superstep 3 with global stats (vtx=1000,finVtx=1000,edges=7508,msgCount=7508,msgBytesCount=66135196,haltComputation=false, checkpointStatus=NONE) and classes (computation=AllShortestPaths,combiner=null,incoming=null,outgoing=null)
2016-05-27 19:33:26,633 INFO [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory: newStore: Created class org.apache.giraph.comm.messages.ByteArrayMessagesPerVertexStore for vertex id class org.apache.hadoop.io.Text and message value class VertexDistanceArrayWritable and no combiner
2016-05-27 19:33:26,659 WARN [main-EventThread] org.apache.giraph.bsp.BspService: process: Unknown and unprocessed event (path=/_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/2/_addressesAndPartitions, type=NodeDeleted, state=SyncConnected)
2016-05-27 19:33:26,665 INFO [main-EventThread] org.apache.giraph.worker.BspServiceWorker: processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
2016-05-27 19:33:26,667 WARN [main-EventThread] org.apache.giraph.bsp.BspService: process: Unknown and unprocessed event (path=/_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
2016-05-27 19:33:26,668 INFO [main] org.apache.giraph.worker.BspServiceWorker: registerHealth: Created my health node for attempt=0, superstep=4 with /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/4/_workerHealthyDir/parcom02.cs.du.edu_0 and workerInfo= Worker(hostname=parcom02.cs.du.edu, MRtaskID=0, port=30020)
2016-05-27 19:33:26,681 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: partitionAssignmentsReadyChanged (partitions are assigned)
2016-05-27 19:33:26,685 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Master(hostname=parcom01.cs.du.edu, MRtaskID=2, port=30002)
2016-05-27 19:33:26,685 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Ready for computation on superstep 4 since worker selection and vertex range assignments are done in /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/4/_addressesAndPartitions
2016-05-27 19:33:26,685 INFO [main] org.apache.giraph.comm.netty.NettyClient: connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
2016-05-27 19:33:26,687 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0006, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.077
MBytes/sec sent = 0.0022, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.078
2016-05-27 19:33:26,690 INFO [main] org.apache.giraph.worker.BspServiceWorker: sendWorkerPartitions: Done sending all my partitions.
2016-05-27 19:33:26,691 INFO [main] org.apache.giraph.worker.BspServiceWorker: exchangeVertexPartitions: Done with exchange.
2016-05-27 19:33:26,693 INFO [main] org.apache.giraph.graph.GraphTaskManager: execute: 4 partitions to process with 1 compute thread(s), originally 1 thread(s) on superstep 4
2016-05-27 19:33:34,347 FATAL [netty-server-worker-1] org.apache.giraph.graph.GraphTaskManager: uncaughtException: OverrideExceptionHandler on thread netty-server-worker-1, msg = Java heap space, exiting...
java.lang.OutOfMemoryError: Java heap space
	at org.apache.giraph.utils.UnsafeByteArrayOutputStream.ensureSize(UnsafeByteArrayOutputStream.java:116)
	at org.apache.giraph.utils.UnsafeByteArrayOutputStream.writeFloat(UnsafeByteArrayOutputStream.java:239)
	at org.apache.hadoop.io.FloatWritable.write(FloatWritable.java:49)
	at VertexDistanceWritable.write(VertexDistanceWritable.java:41)
	at org.apache.hadoop.io.ArrayWritable.write(ArrayWritable.java:105)
	at org.apache.giraph.utils.VerboseByteStructMessageWrite.verboseWriteCurrentMessage(VerboseByteStructMessageWrite.java:50)
	at org.apache.giraph.comm.messages.ByteArrayMessagesPerVertexStore.addPartitionMessages(ByteArrayMessagesPerVertexStore.java:127)
	at org.apache.giraph.comm.requests.SendWorkerMessagesRequest.doRequest(SendWorkerMessagesRequest.java:74)
	at org.apache.giraph.comm.netty.handler.WorkerRequestServerHandler.processRequest(WorkerRequestServerHandler.java:62)
	at org.apache.giraph.comm.netty.handler.WorkerRequestServerHandler.processRequest(WorkerRequestServerHandler.java:36)
	at org.apache.giraph.comm.netty.handler.RequestServerHandler.channelRead(RequestServerHandler.java:108)
	at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:338)
	at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:324)
	at org.apache.giraph.comm.netty.handler.RequestDecoder.channelRead(RequestDecoder.java:100)
	at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:338)
	at io.netty.channel.DefaultChannelHandlerContext.access$700(DefaultChannelHandlerContext.java:29)
	at io.netty.channel.DefaultChannelHandlerContext$8.run(DefaultChannelHandlerContext.java:329)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:354)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:353)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:101)
	at java.lang.Thread.run(Thread.java:745)
2016-05-27 19:33:34,353 ERROR [netty-server-worker-1] org.apache.giraph.worker.BspServiceWorker: unregisterHealth: Got failure, unregistering health on /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/4/_workerHealthyDir/parcom02.cs.du.edu_0 on superstep 4
2016-05-27 19:33:34,874 ERROR [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient: Request failed
java.nio.channels.ClosedChannelException
2016-05-27 19:33:35,013 WARN [compute-0] org.apache.giraph.comm.netty.NettyClient: getNextChannel: Unlikely event that the channel [id: 0x37b3bbe6, 0.0.0.0/0.0.0.0:44378 :> parcom03.cs.du.edu/130.253.8.36:30003] was already removed!
2016-05-27 19:33:35,013 INFO [compute-0] org.apache.giraph.comm.netty.NettyClient: getNextChannel: Fixing disconnected channel to parcom03.cs.du.edu/130.253.8.36:30003, open = false, bound = false
2016-05-27 19:33:34,874 FATAL [netty-server-worker-3] org.apache.giraph.graph.GraphTaskManager: uncaughtException: OverrideExceptionHandler on thread netty-server-worker-3, msg = Connection reset by peer, exiting...
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:384)
	at io.netty.buffer.UnpooledUnsafeDirectByteBuf.setBytes(UnpooledUnsafeDirectByteBuf.java:446)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:871)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:208)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:118)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:485)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:452)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:346)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:101)
	at java.lang.Thread.run(Thread.java:745)
2016-05-27 19:33:35,014 ERROR [netty-server-worker-3] org.apache.giraph.worker.BspServiceWorker: unregisterHealth: Got failure, unregistering health on /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/4/_workerHealthyDir/parcom02.cs.du.edu_0 on superstep 4
2016-05-27 19:33:35,013 WARN [netty-client-worker-0] org.apache.giraph.comm.netty.handler.ResponseClientHandler: exceptionCaught: Channel failed with remote address parcom04.cs.du.edu/130.253.8.37:30001
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:384)
	at io.netty.buffer.UnpooledUnsafeDirectByteBuf.setBytes(UnpooledUnsafeDirectByteBuf.java:446)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:871)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:208)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:118)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:485)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:452)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:346)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:101)
	at java.lang.Thread.run(Thread.java:745)
2016-05-27 19:33:35,016 ERROR [netty-server-worker-3] org.apache.giraph.graph.GraphTaskManager: run: Worker failure failed on another RuntimeException, original expection will be rethrown
java.lang.IllegalStateException: unregisterHealth: KeeperException - Couldn't delete /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/4/_workerHealthyDir/parcom02.cs.du.edu_0
	at org.apache.giraph.worker.BspServiceWorker.unregisterHealth(BspServiceWorker.java:786)
	at org.apache.giraph.worker.BspServiceWorker.failureCleanup(BspServiceWorker.java:794)
	at org.apache.giraph.graph.GraphTaskManager.workerFailureCleanup(GraphTaskManager.java:959)
	at org.apache.giraph.graph.GraphTaskManager$OverrideExceptionHandler.uncaughtException(GraphTaskManager.java:1000)
	at org.apache.giraph.comm.netty.handler.RequestServerHandler.exceptionCaught(RequestServerHandler.java:169)
	at io.netty.channel.DefaultChannelHandlerContext.invokeExceptionCaught(DefaultChannelHandlerContext.java:276)
	at io.netty.channel.DefaultChannelHandlerContext.fireExceptionCaught(DefaultChannelHandlerContext.java:254)
	at io.netty.channel.ChannelInboundHandlerAdapter.exceptionCaught(ChannelInboundHandlerAdapter.java:131)
	at io.netty.channel.DefaultChannelHandlerContext.invokeExceptionCaught(DefaultChannelHandlerContext.java:276)
	at io.netty.channel.DefaultChannelHandlerContext.access$500(DefaultChannelHandlerContext.java:29)
	at io.netty.channel.DefaultChannelHandlerContext$6.run(DefaultChannelHandlerContext.java:260)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:354)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:353)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:101)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/4/_workerHealthyDir/parcom02.cs.du.edu_0
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:873)
	at org.apache.giraph.zk.ZooKeeperExt.deleteExt(ZooKeeperExt.java:302)
	at org.apache.giraph.worker.BspServiceWorker.unregisterHealth(BspServiceWorker.java:780)
	... 14 more
2016-05-27 19:33:35,017 INFO [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient: Using Netty without authentication.



Container: container_1464147437282_0417_01_000005 on parcom03.cs.du.edu_44763
===============================================================================
LogType:stderr
Log Upload Time:27-May-2016 19:33:43
LogLength:911
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/giraph-1.1.0/giraph-core/target/giraph-1.1.0-for-hadoop-2.6.0-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/giraph-1.1.0/giraph-examples/target/giraph-examples-1.1.0-for-hadoop-2.6.0-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

LogType:stdout
Log Upload Time:27-May-2016 19:33:43
LogLength:0
Log Contents:

LogType:syslog
Log Upload Time:27-May-2016 19:33:43
LogLength:55743
Log Contents:
2016-05-27 19:33:13,211 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-05-27 19:33:13,298 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-05-27 19:33:13,370 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-05-27 19:33:13,370 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2016-05-27 19:33:13,381 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2016-05-27 19:33:13,381 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1464147437282_0417, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@604752dd)
2016-05-27 19:33:13,492 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2016-05-27 19:33:13,762 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417
2016-05-27 19:33:14,210 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-05-27 19:33:14,727 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-05-27 19:33:14,894 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2016-05-27 19:33:14,911 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
2016-05-27 19:33:14,943 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-05-27 19:33:14,943 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-05-27 19:33:14,943 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: job.local.dir is deprecated. Instead, use mapreduce.job.local.dir
2016-05-27 19:33:14,950 INFO [main] org.apache.giraph.zk.ZooKeeperManager: createCandidateStamp: Made the directory _bsp/_defaultZkManagerDir/job_1464147437282_0417
2016-05-27 19:33:14,951 INFO [main] org.apache.giraph.zk.ZooKeeperManager: createCandidateStamp: Made the directory _bsp/_defaultZkManagerDir/job_1464147437282_0417/_zkServer
2016-05-27 19:33:14,958 INFO [main] org.apache.giraph.zk.ZooKeeperManager: createCandidateStamp: Creating my filestamp _bsp/_defaultZkManagerDir/job_1464147437282_0417/_task/parcom03.cs.du.edu 3
2016-05-27 19:33:14,985 INFO [main] org.apache.giraph.zk.ZooKeeperManager: getZooKeeperServerList: For task 3, got file 'null' (polling period is 3000)
2016-05-27 19:33:17,986 INFO [main] org.apache.giraph.zk.ZooKeeperManager: getZooKeeperServerList: For task 3, got file 'zkServerList_parcom01.cs.du.edu 2 ' (polling period is 3000)
2016-05-27 19:33:17,986 INFO [main] org.apache.giraph.zk.ZooKeeperManager: getZooKeeperServerList: Found [parcom01.cs.du.edu, 2] 2 hosts in filename 'zkServerList_parcom01.cs.du.edu 2 '
2016-05-27 19:33:17,988 INFO [main] org.apache.giraph.zk.ZooKeeperManager: onlineZooKeeperSErvers: Empty directory _bsp/_defaultZkManagerDir/job_1464147437282_0417/_zkServer, waiting 3000 msecs.
2016-05-27 19:33:20,989 INFO [main] org.apache.giraph.zk.ZooKeeperManager: onlineZooKeeperSErvers: Empty directory _bsp/_defaultZkManagerDir/job_1464147437282_0417/_zkServer, waiting 3000 msecs.
2016-05-27 19:33:23,991 INFO [main] org.apache.giraph.zk.ZooKeeperManager: onlineZooKeeperServers: Got [parcom01.cs.du.edu] 1 hosts from 1 ready servers when 1 required (polling period is 3000) on attempt 2
2016-05-27 19:33:23,994 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Starting up BspServiceMaster (master thread)...
2016-05-27 19:33:24,020 INFO [main] org.apache.giraph.bsp.BspService: BspService: Path to create to halt is /_hadoopBsp/job_1464147437282_0417/_haltComputation
2016-05-27 19:33:24,020 INFO [main] org.apache.giraph.bsp.BspService: BspService: Connecting to ZooKeeper with job job_1464147437282_0417, 3 on parcom01.cs.du.edu:22181
2016-05-27 19:33:24,027 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
2016-05-27 19:33:24,027 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:host.name=parcom03.cs.du.edu
2016-05-27 19:33:24,027 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:java.version=1.7.0_95
2016-05-27 19:33:24,027 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2016-05-27 19:33:24,027 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
2016-05-27 19:33:24,027 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:java.class.path=/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000005:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000005/AllShortestPaths.jar:/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000005/giraph-1.1.0-for-hadoop-2.6.0.jar:/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000005/job.jar:/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000005/conf:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/giraph-1.1.0-for-hadoop-2.6.0-jar-with-dependencies.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/giraph-examples-1.1.0-for-hadoop-2.6.0-jar-with-dependencies.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar
2016-05-27 19:33:24,027 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:java.library.path=/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000005:/usr/local/hadoop-2.6.0/lib/native:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2016-05-27 19:33:24,027 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000005/tmp
2016-05-27 19:33:24,027 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2016-05-27 19:33:24,027 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:os.name=Linux
2016-05-27 19:33:24,027 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:os.arch=amd64
2016-05-27 19:33:24,027 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:os.version=3.2.0-4-amd64
2016-05-27 19:33:24,027 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:user.name=hduser
2016-05-27 19:33:24,027 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:user.home=/home/hduser
2016-05-27 19:33:24,027 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:user.dir=/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000005
2016-05-27 19:33:24,028 INFO [main] org.apache.zookeeper.ZooKeeper: Initiating client connection, connectString=parcom01.cs.du.edu:22181 sessionTimeout=60000 watcher=org.apache.giraph.master.BspServiceMaster@2f069e96
2016-05-27 19:33:24,048 INFO [main-SendThread(parcom01.cs.du.edu:22181)] org.apache.zookeeper.ClientCnxn: Opening socket connection to server parcom01.cs.du.edu/130.253.8.34:22181. Will not attempt to authenticate using SASL (unknown error)
2016-05-27 19:33:24,048 INFO [main-SendThread(parcom01.cs.du.edu:22181)] org.apache.zookeeper.ClientCnxn: Socket connection established to parcom01.cs.du.edu/130.253.8.34:22181, initiating session
2016-05-27 19:33:24,053 INFO [main-SendThread(parcom01.cs.du.edu:22181)] org.apache.zookeeper.ClientCnxn: Session establishment complete on server parcom01.cs.du.edu/130.253.8.34:22181, sessionid = 0x154f4fe78fa0006, negotiated timeout = 600000
2016-05-27 19:33:24,054 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: Asynchronous connection complete.
2016-05-27 19:33:24,062 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Starting up BspServiceWorker...
2016-05-27 19:33:24,068 INFO [main] org.apache.giraph.bsp.BspService: BspService: Path to create to halt is /_hadoopBsp/job_1464147437282_0417/_haltComputation
2016-05-27 19:33:24,068 INFO [main] org.apache.giraph.bsp.BspService: BspService: Connecting to ZooKeeper with job job_1464147437282_0417, 3 on parcom01.cs.du.edu:22181
2016-05-27 19:33:24,068 INFO [main] org.apache.zookeeper.ZooKeeper: Initiating client connection, connectString=parcom01.cs.du.edu:22181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@53dea0db
2016-05-27 19:33:24,068 INFO [main-SendThread(parcom01.cs.du.edu:22181)] org.apache.zookeeper.ClientCnxn: Opening socket connection to server parcom01.cs.du.edu/130.253.8.34:22181. Will not attempt to authenticate using SASL (unknown error)
2016-05-27 19:33:24,069 INFO [main-SendThread(parcom01.cs.du.edu:22181)] org.apache.zookeeper.ClientCnxn: Socket connection established to parcom01.cs.du.edu/130.253.8.34:22181, initiating session
2016-05-27 19:33:24,070 INFO [main-SendThread(parcom01.cs.du.edu:22181)] org.apache.zookeeper.ClientCnxn: Session establishment complete on server parcom01.cs.du.edu/130.253.8.34:22181, sessionid = 0x154f4fe78fa0007, negotiated timeout = 600000
2016-05-27 19:33:24,070 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: Asynchronous connection complete.
2016-05-27 19:33:24,076 INFO [org.apache.giraph.master.MasterThread] org.apache.giraph.bsp.BspService: getJobState: Job state already exists (/_hadoopBsp/job_1464147437282_0417/_masterJobState)
2016-05-27 19:33:24,080 INFO [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster: becomeMaster: First child is '/_hadoopBsp/job_1464147437282_0417/_masterElectionDir/parcom01.cs.du.edu_20000000000' and my bid is '/_hadoopBsp/job_1464147437282_0417/_masterElectionDir/parcom03.cs.du.edu_30000000003'
2016-05-27 19:33:24,080 INFO [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster: becomeMaster: Waiting to become the master...
2016-05-27 19:33:24,134 INFO [main] org.apache.giraph.comm.netty.NettyServer: NettyServer: Using execution group with 8 threads for requestFrameDecoder.
2016-05-27 19:33:24,148 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2016-05-27 19:33:24,180 INFO [main] org.apache.giraph.comm.netty.NettyServer: start: Started server communication server: parcom03.cs.du.edu/130.253.8.36:30003 with up to 16 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
2016-05-27 19:33:24,184 INFO [main] org.apache.giraph.comm.netty.NettyClient: NettyClient: Using execution handler with 8 threads after request-encoder.
2016-05-27 19:33:24,194 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Registering health of this worker...
2016-05-27 19:33:24,200 INFO [main] org.apache.giraph.bsp.BspService: getJobState: Job state already exists (/_hadoopBsp/job_1464147437282_0417/_masterJobState)
2016-05-27 19:33:24,201 INFO [main] org.apache.giraph.bsp.BspService: getApplicationAttempt: Node /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir already exists!
2016-05-27 19:33:24,203 INFO [main] org.apache.giraph.bsp.BspService: getApplicationAttempt: Node /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir already exists!
2016-05-27 19:33:24,207 INFO [main] org.apache.giraph.worker.BspServiceWorker: registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/parcom03.cs.du.edu_3 and workerInfo= Worker(hostname=parcom03.cs.du.edu, MRtaskID=3, port=30003)
2016-05-27 19:33:24,296 INFO [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer: start: Using Netty without authentication.
2016-05-27 19:33:24,297 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: partitionAssignmentsReadyChanged (partitions are assigned)
2016-05-27 19:33:24,303 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Master(hostname=parcom01.cs.du.edu, MRtaskID=2, port=30002)
2016-05-27 19:33:24,303 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Ready for computation on superstep -1 since worker selection and vertex range assignments are done in /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/-1/_addressesAndPartitions
2016-05-27 19:33:24,320 INFO [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient: Using Netty without authentication.
2016-05-27 19:33:24,320 INFO [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient: Using Netty without authentication.
2016-05-27 19:33:24,324 INFO [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient: Using Netty without authentication.
2016-05-27 19:33:24,325 INFO [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient: Using Netty without authentication.
2016-05-27 19:33:24,334 INFO [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer: start: Using Netty without authentication.
2016-05-27 19:33:24,339 INFO [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder: decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0001, ave received req MBytes = 0.0001, secs waited = 1.4643991E9
2016-05-27 19:33:24,345 INFO [main] org.apache.giraph.comm.netty.NettyClient: connectAllAddresses: Successfully added 4 connections, (4 total connected) 0 failed, 0 failures total.
2016-05-27 19:33:24,347 INFO [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer: start: Using Netty without authentication.
2016-05-27 19:33:24,361 INFO [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer: start: Using Netty without authentication.
2016-05-27 19:33:24,387 INFO [main] org.apache.giraph.worker.BspServiceWorker: loadInputSplits: Using 1 thread(s), originally 1 threads(s) for 4 total splits.
2016-05-27 19:33:24,396 INFO [load-0] org.apache.giraph.worker.InputSplitsHandler: reserveInputSplit: Reserved input split path /_hadoopBsp/job_1464147437282_0417/_edgeInputSplitDir/1, overall roughly 0.0% input splits reserved
2016-05-27 19:33:24,397 INFO [load-0] org.apache.giraph.worker.InputSplitsCallable: getInputSplit: Reserved /_hadoopBsp/job_1464147437282_0417/_edgeInputSplitDir/1 from ZooKeeper and got input split 'hdfs://parcom01.cs.du.edu:54410/u/home/maximkolb/Comp3705Processing/svn/Program4/Job1Output/part-r-00001:0+26881'
2016-05-27 19:33:24,399 INFO [load-0] UndirectedTextEdgeInputFormat: createEdgeReader called
2016-05-27 19:33:24,516 INFO [load-0] org.apache.giraph.worker.InputSplitsCallable: loadFromInputSplit: Finished loading /_hadoopBsp/job_1464147437282_0417/_edgeInputSplitDir/1 (v=0, e=2090)
2016-05-27 19:33:24,524 INFO [load-0] org.apache.giraph.worker.InputSplitsCallable: call: Loaded 1 input splits in 0.13626195 secs, (v=0, e=2090) 0.0 vertices/sec, 15338.104 edges/sec
2016-05-27 19:33:24,572 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0009, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.041
MBytes/sec sent = 0.7089, MBytesSent = 0.0298, ave sent req MBytes = 0.0099, secs waited = 0.041
2016-05-27 19:33:24,572 INFO [main] org.apache.giraph.worker.BspServiceWorker: setup: Finally loaded a total of (v=0, e=2090)
2016-05-27 19:33:24,709 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: edgeInputSplitsAllDoneChanged (all edges sent from input splits)
2016-05-27 19:33:24,712 INFO [main] org.apache.giraph.edge.AbstractEdgeStore: moveEdgesToVertices: Moving incoming edges to vertices.
2016-05-27 19:33:24,735 INFO [main] org.apache.giraph.edge.AbstractEdgeStore: moveEdgesToVertices: Finished moving incoming edges to vertices.
2016-05-27 19:33:24,737 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 87.44M / 145.50M / 178.00M
2016-05-27 19:33:24,738 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.207
MBytes/sec sent = 0.1431, MBytesSent = 0.0298, ave sent req MBytes = 0.0099, secs waited = 0.207
2016-05-27 19:33:24,738 INFO [main] org.apache.giraph.worker.WorkerAggregatorHandler: finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
2016-05-27 19:33:24,820 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0006, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.019
MBytes/sec sent = 0.0012, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.019
2016-05-27 19:33:24,821 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 87.15M / 145.50M / 178.00M
2016-05-27 19:33:24,830 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: (waiting for rest of workers) ALL_EXCEPT_ZOOKEEPER - Attempt=0, Superstep=-1
2016-05-27 19:33:24,860 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: superstepFinished signaled
2016-05-27 19:33:24,863 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Completed superstep -1 with global stats (vtx=1000,finVtx=0,edges=7508,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=AllShortestPaths,combiner=null,incoming=null,outgoing=null)
2016-05-27 19:33:24,866 INFO [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory: newStore: Created class org.apache.giraph.comm.messages.ByteArrayMessagesPerVertexStore for vertex id class org.apache.hadoop.io.Text and message value class VertexDistanceArrayWritable and no combiner
2016-05-27 19:33:24,866 INFO [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory: newStore: Created class org.apache.giraph.comm.messages.ByteArrayMessagesPerVertexStore for vertex id class org.apache.hadoop.io.Text and message value class VertexDistanceArrayWritable and no combiner
2016-05-27 19:33:24,868 WARN [main-EventThread] org.apache.giraph.bsp.BspService: process: Unknown and unprocessed event (path=/_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
2016-05-27 19:33:24,873 INFO [main] org.apache.giraph.worker.BspServiceWorker: registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/parcom03.cs.du.edu_3 and workerInfo= Worker(hostname=parcom03.cs.du.edu, MRtaskID=3, port=30003)
2016-05-27 19:33:24,901 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: partitionAssignmentsReadyChanged (partitions are assigned)
2016-05-27 19:33:24,904 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Master(hostname=parcom01.cs.du.edu, MRtaskID=2, port=30002)
2016-05-27 19:33:24,904 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Ready for computation on superstep 0 since worker selection and vertex range assignments are done in /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/0/_addressesAndPartitions
2016-05-27 19:33:24,904 INFO [main] org.apache.giraph.comm.netty.NettyClient: connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
2016-05-27 19:33:24,905 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.104
MBytes/sec sent = 0.0002, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.104
2016-05-27 19:33:24,907 INFO [main] org.apache.giraph.worker.BspServiceWorker: sendWorkerPartitions: Done sending all my partitions.
2016-05-27 19:33:24,908 INFO [main] org.apache.giraph.worker.BspServiceWorker: exchangeVertexPartitions: Done with exchange.
2016-05-27 19:33:24,912 INFO [main-EventThread] org.apache.giraph.worker.BspServiceWorker: processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
2016-05-27 19:33:24,922 INFO [main] org.apache.giraph.graph.GraphTaskManager: execute: 4 partitions to process with 1 compute thread(s), originally 1 thread(s) on superstep 0
2016-05-27 19:33:24,988 INFO [compute-0] org.apache.giraph.graph.ComputeCallable: call: Computation took 0.06480652 secs for 4 partitions on superstep 0.  Flushing started
2016-05-27 19:33:25,007 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 81.92M / 145.50M / 178.00M
2016-05-27 19:33:25,047 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0009, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.042
MBytes/sec sent = 0.7596, MBytesSent = 0.0327, ave sent req MBytes = 0.0109, secs waited = 0.042
2016-05-27 19:33:25,047 INFO [main] org.apache.giraph.worker.WorkerAggregatorHandler: finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
2016-05-27 19:33:25,131 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0062, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
2016-05-27 19:33:25,132 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Superstep 0, messages = 1882 , message bytes = 45376 , Memory (free/total/max) = 81.63M / 145.50M / 178.00M
2016-05-27 19:33:25,134 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: (waiting for rest of workers) ALL_EXCEPT_ZOOKEEPER - Attempt=0, Superstep=0
2016-05-27 19:33:25,148 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: superstepFinished signaled
2016-05-27 19:33:25,153 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Completed superstep 0 with global stats (vtx=1000,finVtx=1000,edges=7508,msgCount=7508,msgBytesCount=181024,haltComputation=false, checkpointStatus=NONE) and classes (computation=AllShortestPaths,combiner=null,incoming=null,outgoing=null)
2016-05-27 19:33:25,153 INFO [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory: newStore: Created class org.apache.giraph.comm.messages.ByteArrayMessagesPerVertexStore for vertex id class org.apache.hadoop.io.Text and message value class VertexDistanceArrayWritable and no combiner
2016-05-27 19:33:25,175 INFO [main] org.apache.giraph.worker.BspServiceWorker: registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/parcom03.cs.du.edu_3 and workerInfo= Worker(hostname=parcom03.cs.du.edu, MRtaskID=3, port=30003)
2016-05-27 19:33:25,190 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: partitionAssignmentsReadyChanged (partitions are assigned)
2016-05-27 19:33:25,194 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Master(hostname=parcom01.cs.du.edu, MRtaskID=2, port=30002)
2016-05-27 19:33:25,194 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Ready for computation on superstep 1 since worker selection and vertex range assignments are done in /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/1/_addressesAndPartitions
2016-05-27 19:33:25,195 INFO [main] org.apache.giraph.comm.netty.NettyClient: connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
2016-05-27 19:33:25,195 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.065
MBytes/sec sent = 0.0004, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.065
2016-05-27 19:33:25,197 INFO [main] org.apache.giraph.worker.BspServiceWorker: sendWorkerPartitions: Done sending all my partitions.
2016-05-27 19:33:25,199 INFO [main] org.apache.giraph.worker.BspServiceWorker: exchangeVertexPartitions: Done with exchange.
2016-05-27 19:33:25,204 INFO [main] org.apache.giraph.graph.GraphTaskManager: execute: 4 partitions to process with 1 compute thread(s), originally 1 thread(s) on superstep 1
2016-05-27 19:33:25,375 INFO [compute-0] org.apache.giraph.graph.ComputeCallable: call: Computation took 0.17114067 secs for 4 partitions on superstep 1.  Flushing started
2016-05-27 19:33:25,388 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 120.29M / 145.50M / 178.00M
2016-05-27 19:33:25,414 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.038
MBytes/sec sent = 4.0137, MBytesSent = 0.1565, ave sent req MBytes = 0.0522, secs waited = 0.038
2016-05-27 19:33:25,414 INFO [main] org.apache.giraph.worker.WorkerAggregatorHandler: finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
2016-05-27 19:33:25,453 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0062, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
2016-05-27 19:33:25,453 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Superstep 1, messages = 1882 , message bytes = 218104 , Memory (free/total/max) = 119.22M / 145.50M / 178.00M
2016-05-27 19:33:25,456 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: (waiting for rest of workers) ALL_EXCEPT_ZOOKEEPER - Attempt=0, Superstep=1
2016-05-27 19:33:25,465 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: superstepFinished signaled
2016-05-27 19:33:25,468 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Completed superstep 1 with global stats (vtx=1000,finVtx=1000,edges=7508,msgCount=7508,msgBytesCount=861712,haltComputation=false, checkpointStatus=NONE) and classes (computation=AllShortestPaths,combiner=null,incoming=null,outgoing=null)
2016-05-27 19:33:25,468 INFO [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory: newStore: Created class org.apache.giraph.comm.messages.ByteArrayMessagesPerVertexStore for vertex id class org.apache.hadoop.io.Text and message value class VertexDistanceArrayWritable and no combiner
2016-05-27 19:33:25,493 INFO [main] org.apache.giraph.worker.BspServiceWorker: registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/parcom03.cs.du.edu_3 and workerInfo= Worker(hostname=parcom03.cs.du.edu, MRtaskID=3, port=30003)
2016-05-27 19:33:25,496 WARN [main-EventThread] org.apache.giraph.bsp.BspService: process: Unknown and unprocessed event (path=/_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/0/_addressesAndPartitions, type=NodeDeleted, state=SyncConnected)
2016-05-27 19:33:25,503 WARN [main-EventThread] org.apache.giraph.bsp.BspService: process: Unknown and unprocessed event (path=/_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
2016-05-27 19:33:25,520 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: partitionAssignmentsReadyChanged (partitions are assigned)
2016-05-27 19:33:25,526 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Master(hostname=parcom01.cs.du.edu, MRtaskID=2, port=30002)
2016-05-27 19:33:25,526 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Ready for computation on superstep 2 since worker selection and vertex range assignments are done in /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/2/_addressesAndPartitions
2016-05-27 19:33:25,526 INFO [main] org.apache.giraph.comm.netty.NettyClient: connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
2016-05-27 19:33:25,527 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.075
MBytes/sec sent = 0.0003, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.075
2016-05-27 19:33:25,530 INFO [main] org.apache.giraph.worker.BspServiceWorker: sendWorkerPartitions: Done sending all my partitions.
2016-05-27 19:33:25,533 INFO [main] org.apache.giraph.worker.BspServiceWorker: exchangeVertexPartitions: Done with exchange.
2016-05-27 19:33:25,537 INFO [main] org.apache.giraph.graph.GraphTaskManager: execute: 4 partitions to process with 1 compute thread(s), originally 1 thread(s) on superstep 2
2016-05-27 19:33:25,662 INFO [compute-0] org.apache.giraph.graph.ComputeCallable: call: Computation took 0.1245976 secs for 4 partitions on superstep 2.  Flushing started
2016-05-27 19:33:25,670 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 89.22M / 145.50M / 178.00M
2016-05-27 19:33:25,687 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0019, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.02
MBytes/sec sent = 61.1824, MBytesSent = 1.2848, ave sent req MBytes = 0.4283, secs waited = 0.02
2016-05-27 19:33:25,687 INFO [main] org.apache.giraph.worker.WorkerAggregatorHandler: finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
2016-05-27 19:33:25,824 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0041, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
2016-05-27 19:33:25,824 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Superstep 2, messages = 1882 , message bytes = 1796032 , Memory (free/total/max) = 71.65M / 145.50M / 178.00M
2016-05-27 19:33:25,826 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: (waiting for rest of workers) ALL_EXCEPT_ZOOKEEPER - Attempt=0, Superstep=2
2016-05-27 19:33:25,836 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: superstepFinished signaled
2016-05-27 19:33:25,838 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Completed superstep 2 with global stats (vtx=1000,finVtx=1000,edges=7508,msgCount=7508,msgBytesCount=7067968,haltComputation=false, checkpointStatus=NONE) and classes (computation=AllShortestPaths,combiner=null,incoming=null,outgoing=null)
2016-05-27 19:33:25,839 INFO [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory: newStore: Created class org.apache.giraph.comm.messages.ByteArrayMessagesPerVertexStore for vertex id class org.apache.hadoop.io.Text and message value class VertexDistanceArrayWritable and no combiner
2016-05-27 19:33:25,854 INFO [main] org.apache.giraph.worker.BspServiceWorker: registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/parcom03.cs.du.edu_3 and workerInfo= Worker(hostname=parcom03.cs.du.edu, MRtaskID=3, port=30003)
2016-05-27 19:33:25,854 WARN [main-EventThread] org.apache.giraph.bsp.BspService: process: Unknown and unprocessed event (path=/_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/1/_addressesAndPartitions, type=NodeDeleted, state=SyncConnected)
2016-05-27 19:33:25,857 INFO [main-EventThread] org.apache.giraph.worker.BspServiceWorker: processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
2016-05-27 19:33:25,861 WARN [main-EventThread] org.apache.giraph.bsp.BspService: process: Unknown and unprocessed event (path=/_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
2016-05-27 19:33:25,876 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: partitionAssignmentsReadyChanged (partitions are assigned)
2016-05-27 19:33:25,879 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Master(hostname=parcom01.cs.du.edu, MRtaskID=2, port=30002)
2016-05-27 19:33:25,879 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Ready for computation on superstep 3 since worker selection and vertex range assignments are done in /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/3/_addressesAndPartitions
2016-05-27 19:33:25,879 INFO [main] org.apache.giraph.comm.netty.NettyClient: connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
2016-05-27 19:33:25,880 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.058
MBytes/sec sent = 0.0004, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.058
2016-05-27 19:33:25,881 INFO [main] org.apache.giraph.worker.BspServiceWorker: sendWorkerPartitions: Done sending all my partitions.
2016-05-27 19:33:25,883 INFO [main] org.apache.giraph.worker.BspServiceWorker: exchangeVertexPartitions: Done with exchange.
2016-05-27 19:33:25,883 INFO [main-EventThread] org.apache.giraph.worker.BspServiceWorker: processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
2016-05-27 19:33:25,890 INFO [main] org.apache.giraph.graph.GraphTaskManager: execute: 4 partitions to process with 1 compute thread(s), originally 1 thread(s) on superstep 3
2016-05-27 19:33:26,254 INFO [compute-0] org.apache.giraph.graph.ComputeCallable: call: Computation took 0.36352384 secs for 4 partitions on superstep 3.  Flushing started
2016-05-27 19:33:26,255 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 71.19M / 137.00M / 178.00M
2016-05-27 19:33:26,269 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0017, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.049
MBytes/sec sent = 48.6941, MBytesSent = 2.4347, ave sent req MBytes = 0.3478, secs waited = 0.049
2016-05-27 19:33:26,269 INFO [main] org.apache.giraph.worker.WorkerAggregatorHandler: finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
2016-05-27 19:33:26,604 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0041, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
2016-05-27 19:33:26,604 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Superstep 3, messages = 1882 , message bytes = 16897595 , Memory (free/total/max) = 42.05M / 137.50M / 178.00M
2016-05-27 19:33:26,606 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: (waiting for rest of workers) ALL_EXCEPT_ZOOKEEPER - Attempt=0, Superstep=3
2016-05-27 19:33:26,616 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: superstepFinished signaled
2016-05-27 19:33:26,617 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Completed superstep 3 with global stats (vtx=1000,finVtx=1000,edges=7508,msgCount=7508,msgBytesCount=66135196,haltComputation=false, checkpointStatus=NONE) and classes (computation=AllShortestPaths,combiner=null,incoming=null,outgoing=null)
2016-05-27 19:33:26,618 INFO [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory: newStore: Created class org.apache.giraph.comm.messages.ByteArrayMessagesPerVertexStore for vertex id class org.apache.hadoop.io.Text and message value class VertexDistanceArrayWritable and no combiner
2016-05-27 19:33:26,652 WARN [main-EventThread] org.apache.giraph.bsp.BspService: process: Unknown and unprocessed event (path=/_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/2/_addressesAndPartitions, type=NodeDeleted, state=SyncConnected)
2016-05-27 19:33:26,653 INFO [main-EventThread] org.apache.giraph.worker.BspServiceWorker: processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
2016-05-27 19:33:26,653 INFO [main] org.apache.giraph.worker.BspServiceWorker: registerHealth: Created my health node for attempt=0, superstep=4 with /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/4/_workerHealthyDir/parcom03.cs.du.edu_3 and workerInfo= Worker(hostname=parcom03.cs.du.edu, MRtaskID=3, port=30003)
2016-05-27 19:33:26,657 WARN [main-EventThread] org.apache.giraph.bsp.BspService: process: Unknown and unprocessed event (path=/_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
2016-05-27 19:33:26,671 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: partitionAssignmentsReadyChanged (partitions are assigned)
2016-05-27 19:33:26,675 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Master(hostname=parcom01.cs.du.edu, MRtaskID=2, port=30002)
2016-05-27 19:33:26,675 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Ready for computation on superstep 4 since worker selection and vertex range assignments are done in /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/4/_addressesAndPartitions
2016-05-27 19:33:26,675 INFO [main] org.apache.giraph.comm.netty.NettyClient: connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
2016-05-27 19:33:26,676 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.073
MBytes/sec sent = 0.0003, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.074
2016-05-27 19:33:26,677 INFO [main] org.apache.giraph.worker.BspServiceWorker: sendWorkerPartitions: Done sending all my partitions.
2016-05-27 19:33:26,678 INFO [main] org.apache.giraph.worker.BspServiceWorker: exchangeVertexPartitions: Done with exchange.
2016-05-27 19:33:26,679 INFO [main-EventThread] org.apache.giraph.worker.BspServiceWorker: processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
2016-05-27 19:33:26,685 INFO [main] org.apache.giraph.graph.GraphTaskManager: execute: 4 partitions to process with 1 compute thread(s), originally 1 thread(s) on superstep 4
2016-05-27 19:33:33,443 FATAL [netty-server-worker-1] org.apache.giraph.graph.GraphTaskManager: uncaughtException: OverrideExceptionHandler on thread netty-server-worker-1, msg = Java heap space, exiting...
java.lang.OutOfMemoryError: Java heap space
	at org.apache.giraph.utils.UnsafeByteArrayOutputStream.ensureSize(UnsafeByteArrayOutputStream.java:116)
	at org.apache.giraph.utils.UnsafeByteArrayOutputStream.writeFloat(UnsafeByteArrayOutputStream.java:239)
	at org.apache.hadoop.io.FloatWritable.write(FloatWritable.java:49)
	at VertexDistanceWritable.write(VertexDistanceWritable.java:41)
	at org.apache.hadoop.io.ArrayWritable.write(ArrayWritable.java:105)
	at org.apache.giraph.utils.VerboseByteStructMessageWrite.verboseWriteCurrentMessage(VerboseByteStructMessageWrite.java:50)
	at org.apache.giraph.comm.messages.ByteArrayMessagesPerVertexStore.addPartitionMessages(ByteArrayMessagesPerVertexStore.java:127)
	at org.apache.giraph.comm.requests.SendWorkerMessagesRequest.doRequest(SendWorkerMessagesRequest.java:74)
	at org.apache.giraph.comm.netty.handler.WorkerRequestServerHandler.processRequest(WorkerRequestServerHandler.java:62)
	at org.apache.giraph.comm.netty.handler.WorkerRequestServerHandler.processRequest(WorkerRequestServerHandler.java:36)
	at org.apache.giraph.comm.netty.handler.RequestServerHandler.channelRead(RequestServerHandler.java:108)
	at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:338)
	at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:324)
	at org.apache.giraph.comm.netty.handler.RequestDecoder.channelRead(RequestDecoder.java:100)
	at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:338)
	at io.netty.channel.DefaultChannelHandlerContext.access$700(DefaultChannelHandlerContext.java:29)
	at io.netty.channel.DefaultChannelHandlerContext$8.run(DefaultChannelHandlerContext.java:329)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:354)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:353)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:101)
	at java.lang.Thread.run(Thread.java:745)
2016-05-27 19:33:33,445 ERROR [netty-server-worker-1] org.apache.giraph.worker.BspServiceWorker: unregisterHealth: Got failure, unregistering health on /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/4/_workerHealthyDir/parcom03.cs.du.edu_3 on superstep 4



Container: container_1464147437282_0417_01_000003 on parcom04.cs.du.edu_38802
===============================================================================
LogType:stderr
Log Upload Time:27-May-2016 19:33:42
LogLength:911
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/giraph-1.1.0/giraph-core/target/giraph-1.1.0-for-hadoop-2.6.0-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/giraph-1.1.0/giraph-examples/target/giraph-examples-1.1.0-for-hadoop-2.6.0-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

LogType:stdout
Log Upload Time:27-May-2016 19:33:42
LogLength:0
Log Contents:

LogType:syslog
Log Upload Time:27-May-2016 19:33:42
LogLength:58052
Log Contents:
2016-05-27 19:33:12,993 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-05-27 19:33:13,081 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-05-27 19:33:13,157 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-05-27 19:33:13,157 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2016-05-27 19:33:13,167 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2016-05-27 19:33:13,168 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1464147437282_0417, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@6a915c8c)
2016-05-27 19:33:13,274 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2016-05-27 19:33:13,569 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417
2016-05-27 19:33:13,985 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-05-27 19:33:14,488 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-05-27 19:33:14,671 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2016-05-27 19:33:14,694 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
2016-05-27 19:33:14,747 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-05-27 19:33:14,747 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-05-27 19:33:14,748 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: job.local.dir is deprecated. Instead, use mapreduce.job.local.dir
2016-05-27 19:33:14,755 INFO [main] org.apache.giraph.zk.ZooKeeperManager: createCandidateStamp: Made the directory _bsp/_defaultZkManagerDir/job_1464147437282_0417
2016-05-27 19:33:14,756 INFO [main] org.apache.giraph.zk.ZooKeeperManager: createCandidateStamp: Made the directory _bsp/_defaultZkManagerDir/job_1464147437282_0417/_zkServer
2016-05-27 19:33:14,764 INFO [main] org.apache.giraph.zk.ZooKeeperManager: createCandidateStamp: Creating my filestamp _bsp/_defaultZkManagerDir/job_1464147437282_0417/_task/parcom04.cs.du.edu 1
2016-05-27 19:33:14,790 INFO [main] org.apache.giraph.zk.ZooKeeperManager: getZooKeeperServerList: For task 1, got file 'null' (polling period is 3000)
2016-05-27 19:33:17,792 INFO [main] org.apache.giraph.zk.ZooKeeperManager: getZooKeeperServerList: For task 1, got file 'zkServerList_parcom01.cs.du.edu 2 ' (polling period is 3000)
2016-05-27 19:33:17,792 INFO [main] org.apache.giraph.zk.ZooKeeperManager: getZooKeeperServerList: Found [parcom01.cs.du.edu, 2] 2 hosts in filename 'zkServerList_parcom01.cs.du.edu 2 '
2016-05-27 19:33:17,794 INFO [main] org.apache.giraph.zk.ZooKeeperManager: onlineZooKeeperSErvers: Empty directory _bsp/_defaultZkManagerDir/job_1464147437282_0417/_zkServer, waiting 3000 msecs.
2016-05-27 19:33:20,795 INFO [main] org.apache.giraph.zk.ZooKeeperManager: onlineZooKeeperSErvers: Empty directory _bsp/_defaultZkManagerDir/job_1464147437282_0417/_zkServer, waiting 3000 msecs.
2016-05-27 19:33:23,797 INFO [main] org.apache.giraph.zk.ZooKeeperManager: onlineZooKeeperServers: Got [parcom01.cs.du.edu] 1 hosts from 1 ready servers when 1 required (polling period is 3000) on attempt 2
2016-05-27 19:33:23,799 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Starting up BspServiceMaster (master thread)...
2016-05-27 19:33:23,826 INFO [main] org.apache.giraph.bsp.BspService: BspService: Path to create to halt is /_hadoopBsp/job_1464147437282_0417/_haltComputation
2016-05-27 19:33:23,826 INFO [main] org.apache.giraph.bsp.BspService: BspService: Connecting to ZooKeeper with job job_1464147437282_0417, 1 on parcom01.cs.du.edu:22181
2016-05-27 19:33:23,833 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
2016-05-27 19:33:23,833 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:host.name=parcom04.cs.du.edu
2016-05-27 19:33:23,833 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:java.version=1.7.0_95
2016-05-27 19:33:23,833 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2016-05-27 19:33:23,833 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
2016-05-27 19:33:23,833 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:java.class.path=/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000003:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000003/AllShortestPaths.jar:/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000003/giraph-1.1.0-for-hadoop-2.6.0.jar:/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000003/job.jar:/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000003/conf:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/giraph-1.1.0-for-hadoop-2.6.0-jar-with-dependencies.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/giraph-examples-1.1.0-for-hadoop-2.6.0-jar-with-dependencies.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar
2016-05-27 19:33:23,833 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:java.library.path=/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000003:/usr/local/hadoop-2.6.0/lib/native:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2016-05-27 19:33:23,833 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000003/tmp
2016-05-27 19:33:23,833 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2016-05-27 19:33:23,833 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:os.name=Linux
2016-05-27 19:33:23,833 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:os.arch=amd64
2016-05-27 19:33:23,833 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:os.version=3.2.0-4-amd64
2016-05-27 19:33:23,833 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:user.name=hduser
2016-05-27 19:33:23,833 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:user.home=/home/hduser
2016-05-27 19:33:23,833 INFO [main] org.apache.zookeeper.ZooKeeper: Client environment:user.dir=/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/container_1464147437282_0417_01_000003
2016-05-27 19:33:23,834 INFO [main] org.apache.zookeeper.ZooKeeper: Initiating client connection, connectString=parcom01.cs.du.edu:22181 sessionTimeout=60000 watcher=org.apache.giraph.master.BspServiceMaster@2f069e96
2016-05-27 19:33:23,851 INFO [main-SendThread(parcom01.cs.du.edu:22181)] org.apache.zookeeper.ClientCnxn: Opening socket connection to server parcom01.cs.du.edu/130.253.8.34:22181. Will not attempt to authenticate using SASL (unknown error)
2016-05-27 19:33:23,852 INFO [main-SendThread(parcom01.cs.du.edu:22181)] org.apache.zookeeper.ClientCnxn: Socket connection established to parcom01.cs.du.edu/130.253.8.34:22181, initiating session
2016-05-27 19:33:23,858 INFO [main-SendThread(parcom01.cs.du.edu:22181)] org.apache.zookeeper.ClientCnxn: Session establishment complete on server parcom01.cs.du.edu/130.253.8.34:22181, sessionid = 0x154f4fe78fa0004, negotiated timeout = 600000
2016-05-27 19:33:23,860 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: Asynchronous connection complete.
2016-05-27 19:33:23,866 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Starting up BspServiceWorker...
2016-05-27 19:33:23,871 INFO [main] org.apache.giraph.bsp.BspService: BspService: Path to create to halt is /_hadoopBsp/job_1464147437282_0417/_haltComputation
2016-05-27 19:33:23,871 INFO [main] org.apache.giraph.bsp.BspService: BspService: Connecting to ZooKeeper with job job_1464147437282_0417, 1 on parcom01.cs.du.edu:22181
2016-05-27 19:33:23,871 INFO [main] org.apache.zookeeper.ZooKeeper: Initiating client connection, connectString=parcom01.cs.du.edu:22181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@50a139bc
2016-05-27 19:33:23,875 INFO [main-SendThread(parcom01.cs.du.edu:22181)] org.apache.zookeeper.ClientCnxn: Opening socket connection to server parcom01.cs.du.edu/130.253.8.34:22181. Will not attempt to authenticate using SASL (unknown error)
2016-05-27 19:33:23,876 INFO [main-SendThread(parcom01.cs.du.edu:22181)] org.apache.zookeeper.ClientCnxn: Socket connection established to parcom01.cs.du.edu/130.253.8.34:22181, initiating session
2016-05-27 19:33:23,877 INFO [main-SendThread(parcom01.cs.du.edu:22181)] org.apache.zookeeper.ClientCnxn: Session establishment complete on server parcom01.cs.du.edu/130.253.8.34:22181, sessionid = 0x154f4fe78fa0005, negotiated timeout = 600000
2016-05-27 19:33:23,877 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: Asynchronous connection complete.
2016-05-27 19:33:23,885 INFO [org.apache.giraph.master.MasterThread] org.apache.giraph.bsp.BspService: getJobState: Job state already exists (/_hadoopBsp/job_1464147437282_0417/_masterJobState)
2016-05-27 19:33:23,897 INFO [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster: becomeMaster: First child is '/_hadoopBsp/job_1464147437282_0417/_masterElectionDir/parcom01.cs.du.edu_20000000000' and my bid is '/_hadoopBsp/job_1464147437282_0417/_masterElectionDir/parcom04.cs.du.edu_10000000002'
2016-05-27 19:33:23,897 INFO [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster: becomeMaster: Waiting to become the master...
2016-05-27 19:33:23,934 INFO [main] org.apache.giraph.comm.netty.NettyServer: NettyServer: Using execution group with 8 threads for requestFrameDecoder.
2016-05-27 19:33:23,948 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2016-05-27 19:33:23,982 INFO [main] org.apache.giraph.comm.netty.NettyServer: start: Started server communication server: parcom04.cs.du.edu/130.253.8.37:30001 with up to 16 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
2016-05-27 19:33:23,986 INFO [main] org.apache.giraph.comm.netty.NettyClient: NettyClient: Using execution handler with 8 threads after request-encoder.
2016-05-27 19:33:23,994 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Registering health of this worker...
2016-05-27 19:33:23,999 INFO [main] org.apache.giraph.bsp.BspService: getJobState: Job state already exists (/_hadoopBsp/job_1464147437282_0417/_masterJobState)
2016-05-27 19:33:24,000 INFO [main] org.apache.giraph.bsp.BspService: getApplicationAttempt: Node /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir already exists!
2016-05-27 19:33:24,002 INFO [main] org.apache.giraph.bsp.BspService: getApplicationAttempt: Node /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir already exists!
2016-05-27 19:33:24,006 INFO [main] org.apache.giraph.worker.BspServiceWorker: registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/parcom04.cs.du.edu_1 and workerInfo= Worker(hostname=parcom04.cs.du.edu, MRtaskID=1, port=30001)
2016-05-27 19:33:24,066 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: masterElectionChildrenChanged signaled
2016-05-27 19:33:24,068 INFO [org.apache.giraph.master.MasterThread] org.apache.giraph.bsp.BspService: getJobState: Job state already exists (/_hadoopBsp/job_1464147437282_0417/_masterJobState)
2016-05-27 19:33:24,070 INFO [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster: becomeMaster: First child is '/_hadoopBsp/job_1464147437282_0417/_masterElectionDir/parcom01.cs.du.edu_20000000000' and my bid is '/_hadoopBsp/job_1464147437282_0417/_masterElectionDir/parcom04.cs.du.edu_10000000002'
2016-05-27 19:33:24,070 INFO [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster: becomeMaster: Waiting to become the master...
2016-05-27 19:33:24,290 INFO [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer: start: Using Netty without authentication.
2016-05-27 19:33:24,294 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: partitionAssignmentsReadyChanged (partitions are assigned)
2016-05-27 19:33:24,300 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Master(hostname=parcom01.cs.du.edu, MRtaskID=2, port=30002)
2016-05-27 19:33:24,300 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Ready for computation on superstep -1 since worker selection and vertex range assignments are done in /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/-1/_addressesAndPartitions
2016-05-27 19:33:24,302 INFO [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient: Using Netty without authentication.
2016-05-27 19:33:24,312 INFO [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient: Using Netty without authentication.
2016-05-27 19:33:24,312 INFO [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient: Using Netty without authentication.
2016-05-27 19:33:24,317 INFO [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer: start: Using Netty without authentication.
2016-05-27 19:33:24,328 INFO [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient: Using Netty without authentication.
2016-05-27 19:33:24,336 INFO [main] org.apache.giraph.comm.netty.NettyClient: connectAllAddresses: Successfully added 4 connections, (4 total connected) 0 failed, 0 failures total.
2016-05-27 19:33:24,337 INFO [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder: decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0001, ave received req MBytes = 0.0001, secs waited = 1.4643991E9
2016-05-27 19:33:24,343 INFO [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer: start: Using Netty without authentication.
2016-05-27 19:33:24,356 INFO [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer: start: Using Netty without authentication.
2016-05-27 19:33:24,384 INFO [main] org.apache.giraph.worker.BspServiceWorker: loadInputSplits: Using 1 thread(s), originally 1 threads(s) for 4 total splits.
2016-05-27 19:33:24,394 INFO [load-0] org.apache.giraph.worker.InputSplitsHandler: reserveInputSplit: Reserved input split path /_hadoopBsp/job_1464147437282_0417/_edgeInputSplitDir/3, overall roughly 0.0% input splits reserved
2016-05-27 19:33:24,395 INFO [load-0] org.apache.giraph.worker.InputSplitsCallable: getInputSplit: Reserved /_hadoopBsp/job_1464147437282_0417/_edgeInputSplitDir/3 from ZooKeeper and got input split 'hdfs://parcom01.cs.du.edu:54410/u/home/maximkolb/Comp3705Processing/svn/Program4/Job1Output/part-r-00003:0+21446'
2016-05-27 19:33:24,396 INFO [load-0] UndirectedTextEdgeInputFormat: createEdgeReader called
2016-05-27 19:33:24,481 INFO [load-0] org.apache.giraph.worker.InputSplitsCallable: loadFromInputSplit: Finished loading /_hadoopBsp/job_1464147437282_0417/_edgeInputSplitDir/3 (v=0, e=1670)
2016-05-27 19:33:24,485 INFO [load-0] org.apache.giraph.worker.InputSplitsCallable: call: Loaded 1 input splits in 0.100304574 secs, (v=0, e=1670) 0.0 vertices/sec, 16649.291 edges/sec
2016-05-27 19:33:24,550 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0006, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.064
MBytes/sec sent = 0.3712, MBytesSent = 0.0241, ave sent req MBytes = 0.008, secs waited = 0.064
2016-05-27 19:33:24,550 INFO [main] org.apache.giraph.worker.BspServiceWorker: setup: Finally loaded a total of (v=0, e=1670)
2016-05-27 19:33:24,707 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: edgeInputSplitsAllDoneChanged (all edges sent from input splits)
2016-05-27 19:33:24,709 INFO [main] org.apache.giraph.edge.AbstractEdgeStore: moveEdgesToVertices: Moving incoming edges to vertices.
2016-05-27 19:33:24,734 INFO [main] org.apache.giraph.edge.AbstractEdgeStore: moveEdgesToVertices: Finished moving incoming edges to vertices.
2016-05-27 19:33:24,736 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 94.20M / 145.50M / 178.00M
2016-05-27 19:33:24,738 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.251
MBytes/sec sent = 0.0957, MBytesSent = 0.0241, ave sent req MBytes = 0.008, secs waited = 0.252
2016-05-27 19:33:24,738 INFO [main] org.apache.giraph.worker.WorkerAggregatorHandler: finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
2016-05-27 19:33:24,817 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0006, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.021
MBytes/sec sent = 0.0011, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.021
2016-05-27 19:33:24,817 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 93.82M / 145.50M / 178.00M
2016-05-27 19:33:24,828 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: (waiting for rest of workers) ALL_EXCEPT_ZOOKEEPER - Attempt=0, Superstep=-1
2016-05-27 19:33:24,857 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: superstepFinished signaled
2016-05-27 19:33:24,860 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Completed superstep -1 with global stats (vtx=1000,finVtx=0,edges=7508,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=AllShortestPaths,combiner=null,incoming=null,outgoing=null)
2016-05-27 19:33:24,863 INFO [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory: newStore: Created class org.apache.giraph.comm.messages.ByteArrayMessagesPerVertexStore for vertex id class org.apache.hadoop.io.Text and message value class VertexDistanceArrayWritable and no combiner
2016-05-27 19:33:24,864 INFO [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory: newStore: Created class org.apache.giraph.comm.messages.ByteArrayMessagesPerVertexStore for vertex id class org.apache.hadoop.io.Text and message value class VertexDistanceArrayWritable and no combiner
2016-05-27 19:33:24,865 WARN [main-EventThread] org.apache.giraph.bsp.BspService: process: Unknown and unprocessed event (path=/_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
2016-05-27 19:33:24,871 INFO [main] org.apache.giraph.worker.BspServiceWorker: registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/parcom04.cs.du.edu_1 and workerInfo= Worker(hostname=parcom04.cs.du.edu, MRtaskID=1, port=30001)
2016-05-27 19:33:24,898 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: partitionAssignmentsReadyChanged (partitions are assigned)
2016-05-27 19:33:24,903 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Master(hostname=parcom01.cs.du.edu, MRtaskID=2, port=30002)
2016-05-27 19:33:24,903 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Ready for computation on superstep 0 since worker selection and vertex range assignments are done in /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/0/_addressesAndPartitions
2016-05-27 19:33:24,903 INFO [main] org.apache.giraph.comm.netty.NettyClient: connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
2016-05-27 19:33:24,904 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.107
MBytes/sec sent = 0.0002, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.108
2016-05-27 19:33:24,905 INFO [main] org.apache.giraph.worker.BspServiceWorker: sendWorkerPartitions: Done sending all my partitions.
2016-05-27 19:33:24,906 INFO [main] org.apache.giraph.worker.BspServiceWorker: exchangeVertexPartitions: Done with exchange.
2016-05-27 19:33:24,909 INFO [main-EventThread] org.apache.giraph.worker.BspServiceWorker: processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
2016-05-27 19:33:24,917 INFO [main] org.apache.giraph.graph.GraphTaskManager: execute: 4 partitions to process with 1 compute thread(s), originally 1 thread(s) on superstep 0
2016-05-27 19:33:24,974 INFO [compute-0] org.apache.giraph.graph.ComputeCallable: call: Computation took 0.055171777 secs for 4 partitions on superstep 0.  Flushing started
2016-05-27 19:33:24,983 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 87.40M / 145.50M / 178.00M
2016-05-27 19:33:25,015 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0009, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.041
MBytes/sec sent = 0.7674, MBytesSent = 0.0322, ave sent req MBytes = 0.0107, secs waited = 0.041
2016-05-27 19:33:25,015 INFO [main] org.apache.giraph.worker.WorkerAggregatorHandler: finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
2016-05-27 19:33:25,128 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0062, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
2016-05-27 19:33:25,129 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Superstep 0, messages = 1865 , message bytes = 44968 , Memory (free/total/max) = 87.40M / 145.50M / 178.00M
2016-05-27 19:33:25,131 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: (waiting for rest of workers) ALL_EXCEPT_ZOOKEEPER - Attempt=0, Superstep=0
2016-05-27 19:33:25,145 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: superstepFinished signaled
2016-05-27 19:33:25,150 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Completed superstep 0 with global stats (vtx=1000,finVtx=1000,edges=7508,msgCount=7508,msgBytesCount=181024,haltComputation=false, checkpointStatus=NONE) and classes (computation=AllShortestPaths,combiner=null,incoming=null,outgoing=null)
2016-05-27 19:33:25,151 INFO [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory: newStore: Created class org.apache.giraph.comm.messages.ByteArrayMessagesPerVertexStore for vertex id class org.apache.hadoop.io.Text and message value class VertexDistanceArrayWritable and no combiner
2016-05-27 19:33:25,172 INFO [main] org.apache.giraph.worker.BspServiceWorker: registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/parcom04.cs.du.edu_1 and workerInfo= Worker(hostname=parcom04.cs.du.edu, MRtaskID=1, port=30001)
2016-05-27 19:33:25,187 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: partitionAssignmentsReadyChanged (partitions are assigned)
2016-05-27 19:33:25,191 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Master(hostname=parcom01.cs.du.edu, MRtaskID=2, port=30002)
2016-05-27 19:33:25,192 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Ready for computation on superstep 1 since worker selection and vertex range assignments are done in /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/1/_addressesAndPartitions
2016-05-27 19:33:25,192 INFO [main] org.apache.giraph.comm.netty.NettyClient: connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
2016-05-27 19:33:25,192 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.065
MBytes/sec sent = 0.0004, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.065
2016-05-27 19:33:25,194 INFO [main] org.apache.giraph.worker.BspServiceWorker: sendWorkerPartitions: Done sending all my partitions.
2016-05-27 19:33:25,196 INFO [main] org.apache.giraph.worker.BspServiceWorker: exchangeVertexPartitions: Done with exchange.
2016-05-27 19:33:25,196 INFO [main-EventThread] org.apache.giraph.worker.BspServiceWorker: processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
2016-05-27 19:33:25,200 INFO [main] org.apache.giraph.graph.GraphTaskManager: execute: 4 partitions to process with 1 compute thread(s), originally 1 thread(s) on superstep 1
2016-05-27 19:33:25,298 INFO [compute-0] org.apache.giraph.graph.ComputeCallable: call: Computation took 0.09863758 secs for 4 partitions on superstep 1.  Flushing started
2016-05-27 19:33:25,321 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 81.34M / 145.50M / 178.00M
2016-05-27 19:33:25,404 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0004, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.102
MBytes/sec sent = 1.5158, MBytesSent = 0.1561, ave sent req MBytes = 0.052, secs waited = 0.102
2016-05-27 19:33:25,404 INFO [main] org.apache.giraph.worker.WorkerAggregatorHandler: finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
2016-05-27 19:33:25,450 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0062, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
2016-05-27 19:33:25,450 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Superstep 1, messages = 1865 , message bytes = 215848 , Memory (free/total/max) = 79.06M / 145.50M / 178.00M
2016-05-27 19:33:25,452 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: (waiting for rest of workers) ALL_EXCEPT_ZOOKEEPER - Attempt=0, Superstep=1
2016-05-27 19:33:25,463 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: superstepFinished signaled
2016-05-27 19:33:25,469 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Completed superstep 1 with global stats (vtx=1000,finVtx=1000,edges=7508,msgCount=7508,msgBytesCount=861712,haltComputation=false, checkpointStatus=NONE) and classes (computation=AllShortestPaths,combiner=null,incoming=null,outgoing=null)
2016-05-27 19:33:25,470 INFO [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory: newStore: Created class org.apache.giraph.comm.messages.ByteArrayMessagesPerVertexStore for vertex id class org.apache.hadoop.io.Text and message value class VertexDistanceArrayWritable and no combiner
2016-05-27 19:33:25,493 WARN [main-EventThread] org.apache.giraph.bsp.BspService: process: Unknown and unprocessed event (path=/_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/0/_addressesAndPartitions, type=NodeDeleted, state=SyncConnected)
2016-05-27 19:33:25,494 INFO [main] org.apache.giraph.worker.BspServiceWorker: registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/parcom04.cs.du.edu_1 and workerInfo= Worker(hostname=parcom04.cs.du.edu, MRtaskID=1, port=30001)
2016-05-27 19:33:25,500 WARN [main-EventThread] org.apache.giraph.bsp.BspService: process: Unknown and unprocessed event (path=/_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
2016-05-27 19:33:25,518 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: partitionAssignmentsReadyChanged (partitions are assigned)
2016-05-27 19:33:25,523 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Master(hostname=parcom01.cs.du.edu, MRtaskID=2, port=30002)
2016-05-27 19:33:25,523 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Ready for computation on superstep 2 since worker selection and vertex range assignments are done in /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/2/_addressesAndPartitions
2016-05-27 19:33:25,523 INFO [main] org.apache.giraph.comm.netty.NettyClient: connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
2016-05-27 19:33:25,524 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.075
MBytes/sec sent = 0.0003, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.075
2016-05-27 19:33:25,527 INFO [main] org.apache.giraph.worker.BspServiceWorker: sendWorkerPartitions: Done sending all my partitions.
2016-05-27 19:33:25,529 INFO [main] org.apache.giraph.worker.BspServiceWorker: exchangeVertexPartitions: Done with exchange.
2016-05-27 19:33:25,530 INFO [main-EventThread] org.apache.giraph.worker.BspServiceWorker: processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
2016-05-27 19:33:25,534 INFO [main] org.apache.giraph.graph.GraphTaskManager: execute: 4 partitions to process with 1 compute thread(s), originally 1 thread(s) on superstep 2
2016-05-27 19:33:25,682 INFO [compute-0] org.apache.giraph.graph.ComputeCallable: call: Computation took 0.14839767 secs for 4 partitions on superstep 2.  Flushing started
2016-05-27 19:33:25,695 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 82.85M / 134.50M / 178.00M
2016-05-27 19:33:25,714 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0012, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.03
MBytes/sec sent = 41.7873, MBytesSent = 1.2954, ave sent req MBytes = 0.4318, secs waited = 0.03
2016-05-27 19:33:25,714 INFO [main] org.apache.giraph.worker.WorkerAggregatorHandler: finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
2016-05-27 19:33:25,821 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0062, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
2016-05-27 19:33:25,821 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Superstep 2, messages = 1865 , message bytes = 1784992 , Memory (free/total/max) = 118.72M / 140.00M / 178.00M
2016-05-27 19:33:25,823 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: (waiting for rest of workers) ALL_EXCEPT_ZOOKEEPER - Attempt=0, Superstep=2
2016-05-27 19:33:25,833 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: superstepFinished signaled
2016-05-27 19:33:25,835 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Completed superstep 2 with global stats (vtx=1000,finVtx=1000,edges=7508,msgCount=7508,msgBytesCount=7067968,haltComputation=false, checkpointStatus=NONE) and classes (computation=AllShortestPaths,combiner=null,incoming=null,outgoing=null)
2016-05-27 19:33:25,835 INFO [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory: newStore: Created class org.apache.giraph.comm.messages.ByteArrayMessagesPerVertexStore for vertex id class org.apache.hadoop.io.Text and message value class VertexDistanceArrayWritable and no combiner
2016-05-27 19:33:25,851 INFO [main] org.apache.giraph.worker.BspServiceWorker: registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/parcom04.cs.du.edu_1 and workerInfo= Worker(hostname=parcom04.cs.du.edu, MRtaskID=1, port=30001)
2016-05-27 19:33:25,852 WARN [main-EventThread] org.apache.giraph.bsp.BspService: process: Unknown and unprocessed event (path=/_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/1/_addressesAndPartitions, type=NodeDeleted, state=SyncConnected)
2016-05-27 19:33:25,858 WARN [main-EventThread] org.apache.giraph.bsp.BspService: process: Unknown and unprocessed event (path=/_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
2016-05-27 19:33:25,873 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: partitionAssignmentsReadyChanged (partitions are assigned)
2016-05-27 19:33:25,878 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Master(hostname=parcom01.cs.du.edu, MRtaskID=2, port=30002)
2016-05-27 19:33:25,878 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Ready for computation on superstep 3 since worker selection and vertex range assignments are done in /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/3/_addressesAndPartitions
2016-05-27 19:33:25,878 INFO [main] org.apache.giraph.comm.netty.NettyClient: connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
2016-05-27 19:33:25,879 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.06
MBytes/sec sent = 0.0004, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.06
2016-05-27 19:33:25,881 INFO [main] org.apache.giraph.worker.BspServiceWorker: sendWorkerPartitions: Done sending all my partitions.
2016-05-27 19:33:25,883 INFO [main] org.apache.giraph.worker.BspServiceWorker: exchangeVertexPartitions: Done with exchange.
2016-05-27 19:33:25,883 INFO [main-EventThread] org.apache.giraph.worker.BspServiceWorker: processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
2016-05-27 19:33:25,886 INFO [main] org.apache.giraph.graph.GraphTaskManager: execute: 4 partitions to process with 1 compute thread(s), originally 1 thread(s) on superstep 3
2016-05-27 19:33:26,229 INFO [compute-0] org.apache.giraph.graph.ComputeCallable: call: Computation took 0.34208485 secs for 4 partitions on superstep 3.  Flushing started
2016-05-27 19:33:26,232 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 70.99M / 138.50M / 178.00M
2016-05-27 19:33:26,268 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0009, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.039
MBytes/sec sent = 25.9782, MBytesSent = 1.0391, ave sent req MBytes = 0.3464, secs waited = 0.039
2016-05-27 19:33:26,268 INFO [main] org.apache.giraph.worker.WorkerAggregatorHandler: finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
2016-05-27 19:33:26,601 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0041, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
2016-05-27 19:33:26,601 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Superstep 3, messages = 1865 , message bytes = 16805124 , Memory (free/total/max) = 78.97M / 139.50M / 178.00M
2016-05-27 19:33:26,603 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: (waiting for rest of workers) ALL_EXCEPT_ZOOKEEPER - Attempt=0, Superstep=3
2016-05-27 19:33:26,613 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: superstepFinished signaled
2016-05-27 19:33:26,621 INFO [main] org.apache.giraph.worker.BspServiceWorker: finishSuperstep: Completed superstep 3 with global stats (vtx=1000,finVtx=1000,edges=7508,msgCount=7508,msgBytesCount=66135196,haltComputation=false, checkpointStatus=NONE) and classes (computation=AllShortestPaths,combiner=null,incoming=null,outgoing=null)
2016-05-27 19:33:26,621 INFO [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory: newStore: Created class org.apache.giraph.comm.messages.ByteArrayMessagesPerVertexStore for vertex id class org.apache.hadoop.io.Text and message value class VertexDistanceArrayWritable and no combiner
2016-05-27 19:33:26,647 WARN [main-EventThread] org.apache.giraph.bsp.BspService: process: Unknown and unprocessed event (path=/_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/2/_addressesAndPartitions, type=NodeDeleted, state=SyncConnected)
2016-05-27 19:33:26,650 INFO [main] org.apache.giraph.worker.BspServiceWorker: registerHealth: Created my health node for attempt=0, superstep=4 with /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/4/_workerHealthyDir/parcom04.cs.du.edu_1 and workerInfo= Worker(hostname=parcom04.cs.du.edu, MRtaskID=1, port=30001)
2016-05-27 19:33:26,654 WARN [main-EventThread] org.apache.giraph.bsp.BspService: process: Unknown and unprocessed event (path=/_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
2016-05-27 19:33:26,669 INFO [main-EventThread] org.apache.giraph.bsp.BspService: process: partitionAssignmentsReadyChanged (partitions are assigned)
2016-05-27 19:33:26,672 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Master(hostname=parcom01.cs.du.edu, MRtaskID=2, port=30002)
2016-05-27 19:33:26,672 INFO [main] org.apache.giraph.worker.BspServiceWorker: startSuperstep: Ready for computation on superstep 4 since worker selection and vertex range assignments are done in /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/4/_addressesAndPartitions
2016-05-27 19:33:26,672 INFO [main] org.apache.giraph.comm.netty.NettyClient: connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
2016-05-27 19:33:26,674 INFO [main] org.apache.giraph.comm.netty.NettyClient: waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.075
MBytes/sec sent = 0.0003, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.075
2016-05-27 19:33:26,676 INFO [main] org.apache.giraph.worker.BspServiceWorker: sendWorkerPartitions: Done sending all my partitions.
2016-05-27 19:33:26,677 INFO [main] org.apache.giraph.worker.BspServiceWorker: exchangeVertexPartitions: Done with exchange.
2016-05-27 19:33:26,682 INFO [main] org.apache.giraph.graph.GraphTaskManager: execute: 4 partitions to process with 1 compute thread(s), originally 1 thread(s) on superstep 4
2016-05-27 19:33:33,837 FATAL [netty-server-worker-1] org.apache.giraph.graph.GraphTaskManager: uncaughtException: OverrideExceptionHandler on thread netty-server-worker-1, msg = Java heap space, exiting...
java.lang.OutOfMemoryError: Java heap space
	at org.apache.giraph.utils.UnsafeByteArrayOutputStream.ensureSize(UnsafeByteArrayOutputStream.java:116)
	at org.apache.giraph.utils.UnsafeByteArrayOutputStream.write(UnsafeByteArrayOutputStream.java:167)
	at org.apache.hadoop.io.Text.write(Text.java:331)
	at VertexDistanceWritable.write(VertexDistanceWritable.java:40)
	at org.apache.hadoop.io.ArrayWritable.write(ArrayWritable.java:105)
	at org.apache.giraph.utils.VerboseByteStructMessageWrite.verboseWriteCurrentMessage(VerboseByteStructMessageWrite.java:50)
	at org.apache.giraph.comm.messages.ByteArrayMessagesPerVertexStore.addPartitionMessages(ByteArrayMessagesPerVertexStore.java:127)
	at org.apache.giraph.comm.requests.SendWorkerMessagesRequest.doRequest(SendWorkerMessagesRequest.java:74)
	at org.apache.giraph.comm.netty.handler.WorkerRequestServerHandler.processRequest(WorkerRequestServerHandler.java:62)
	at org.apache.giraph.comm.netty.handler.WorkerRequestServerHandler.processRequest(WorkerRequestServerHandler.java:36)
	at org.apache.giraph.comm.netty.handler.RequestServerHandler.channelRead(RequestServerHandler.java:108)
	at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:338)
	at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:324)
	at org.apache.giraph.comm.netty.handler.RequestDecoder.channelRead(RequestDecoder.java:100)
	at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:338)
	at io.netty.channel.DefaultChannelHandlerContext.access$700(DefaultChannelHandlerContext.java:29)
	at io.netty.channel.DefaultChannelHandlerContext$8.run(DefaultChannelHandlerContext.java:329)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:354)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:353)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:101)
	at java.lang.Thread.run(Thread.java:745)
2016-05-27 19:33:33,839 ERROR [netty-server-worker-1] org.apache.giraph.worker.BspServiceWorker: unregisterHealth: Got failure, unregistering health on /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/4/_workerHealthyDir/parcom04.cs.du.edu_1 on superstep 4
2016-05-27 19:33:34,455 FATAL [netty-server-worker-2] org.apache.giraph.graph.GraphTaskManager: uncaughtException: OverrideExceptionHandler on thread netty-server-worker-2, msg = Connection reset by peer, exiting...
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:384)
	at io.netty.buffer.UnpooledUnsafeDirectByteBuf.setBytes(UnpooledUnsafeDirectByteBuf.java:446)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:871)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:208)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:118)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:485)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:452)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:346)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:101)
	at java.lang.Thread.run(Thread.java:745)
2016-05-27 19:33:34,456 ERROR [netty-server-worker-2] org.apache.giraph.worker.BspServiceWorker: unregisterHealth: Got failure, unregistering health on /_hadoopBsp/job_1464147437282_0417/_applicationAttemptsDir/0/_superstepDir/4/_workerHealthyDir/parcom04.cs.du.edu_1 on superstep 4
2016-05-27 19:33:34,457 ERROR [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient: Request failed
java.nio.channels.ClosedChannelException



Container: container_1464147437282_0417_01_000001 on parcom04.cs.du.edu_38802
===============================================================================
LogType:stderr
Log Upload Time:27-May-2016 19:33:42
LogLength:1133
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/var/opt/hadoop/tmp/nm-local-dir/usercache/maximkolb/appcache/application_1464147437282_0417/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/giraph-1.1.0/giraph-core/target/giraph-1.1.0-for-hadoop-2.6.0-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/giraph-1.1.0/giraph-examples/target/giraph-examples-1.1.0-for-hadoop-2.6.0-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
log4j:WARN No appenders could be found for logger (org.apache.hadoop.ipc.Server).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.

LogType:stdout
Log Upload Time:27-May-2016 19:33:42
LogLength:0
Log Contents:

LogType:syslog
Log Upload Time:27-May-2016 19:33:42
LogLength:44243
Log Contents:
2016-05-27 19:33:06,817 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Created MRAppMaster for application appattempt_1464147437282_0417_000001
2016-05-27 19:33:07,131 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-05-27 19:33:07,162 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Executing with tokens:
2016-05-27 19:33:07,162 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 417 cluster_timestamp: 1464147437282 } attemptId: 1 } keyId: 1109229307)
2016-05-27 19:33:07,345 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Using mapred newApiCommitter.
2016-05-27 19:33:08,011 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter set in config null
2016-05-27 19:33:08,114 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter is org.apache.giraph.io.internal.WrappedVertexOutputFormat$2
2016-05-27 19:33:08,137 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.jobhistory.EventType for class org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler
2016-05-27 19:33:08,138 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher
2016-05-27 19:33:08,139 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskEventDispatcher
2016-05-27 19:33:08,140 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher
2016-05-27 19:33:08,140 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventType for class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler
2016-05-27 19:33:08,146 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.speculate.Speculator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$SpeculatorEventDispatcher
2016-05-27 19:33:08,147 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.rm.ContainerAllocator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter
2016-05-27 19:33:08,148 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncher$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerLauncherRouter
2016-05-27 19:33:08,184 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://parcom01.cs.du.edu:54410]
2016-05-27 19:33:08,202 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://parcom01.cs.du.edu:54410]
2016-05-27 19:33:08,219 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://parcom01.cs.du.edu:54410]
2016-05-27 19:33:08,228 INFO [main] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Emitting job history data to the timeline server is not enabled
2016-05-27 19:33:08,269 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobFinishEvent$Type for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler
2016-05-27 19:33:08,471 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-05-27 19:33:08,525 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-05-27 19:33:08,525 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MRAppMaster metrics system started
2016-05-27 19:33:08,532 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Adding job token for job_1464147437282_0417 to jobTokenSecretManager
2016-05-27 19:33:08,625 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Not uberizing job_1464147437282_0417 because: not enabled;
2016-05-27 19:33:08,639 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Input size for job job_1464147437282_0417 = 0. Number of splits = 4
2016-05-27 19:33:08,639 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Number of reduces for job job_1464147437282_0417 = 0
2016-05-27 19:33:08,640 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1464147437282_0417Job Transitioned from NEW to INITED
2016-05-27 19:33:08,641 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: MRAppMaster launching normal, non-uberized, multi-container job job_1464147437282_0417.
2016-05-27 19:33:08,667 INFO [main] org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-05-27 19:33:08,675 INFO [Socket Reader #1 for port 39001] org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 39001
2016-05-27 19:33:08,721 INFO [main] org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server
2016-05-27 19:33:08,721 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-05-27 19:33:08,722 INFO [IPC Server listener on 39001] org.apache.hadoop.ipc.Server: IPC Server listener on 39001: starting
2016-05-27 19:33:08,723 INFO [main] org.apache.hadoop.mapreduce.v2.app.client.MRClientService: Instantiated MRClientService at parcom04.cs.du.edu/130.253.8.37:39001
2016-05-27 19:33:08,787 INFO [main] org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-05-27 19:33:08,791 INFO [main] org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.mapreduce is not defined
2016-05-27 19:33:08,799 INFO [main] org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-05-27 19:33:08,804 INFO [main] org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context mapreduce
2016-05-27 19:33:08,804 INFO [main] org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context static
2016-05-27 19:33:08,806 INFO [main] org.apache.hadoop.http.HttpServer2: adding path spec: /mapreduce/*
2016-05-27 19:33:08,807 INFO [main] org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2016-05-27 19:33:08,814 INFO [main] org.apache.hadoop.http.HttpServer2: Jetty bound to port 36259
2016-05-27 19:33:08,814 INFO [main] org.mortbay.log: jetty-6.1.26
2016-05-27 19:33:08,841 INFO [main] org.mortbay.log: Extract jar:file:/usr/local/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar!/webapps/mapreduce to /tmp/Jetty_0_0_0_0_36259_mapreduce____hnwubq/webapp
2016-05-27 19:33:09,214 INFO [main] org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:36259
2016-05-27 19:33:09,215 INFO [main] org.apache.hadoop.yarn.webapp.WebApps: Web app /mapreduce started at 36259
2016-05-27 19:33:09,518 INFO [main] org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2016-05-27 19:33:09,521 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator: JOB_CREATE job_1464147437282_0417
2016-05-27 19:33:09,522 INFO [main] org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-05-27 19:33:09,522 INFO [Socket Reader #1 for port 60124] org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 60124
2016-05-27 19:33:09,526 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-05-27 19:33:09,526 INFO [IPC Server listener on 60124] org.apache.hadoop.ipc.Server: IPC Server listener on 60124: starting
2016-05-27 19:33:09,543 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: nodeBlacklistingEnabled:true
2016-05-27 19:33:09,543 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: maxTaskFailuresPerNode is 3
2016-05-27 19:33:09,545 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: blacklistDisablePercent is 33
2016-05-27 19:33:09,589 INFO [main] org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at parcom01.cs.du.edu/130.253.8.34:8030
2016-05-27 19:33:09,648 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: maxContainerCapability: <memory:8192, vCores:32>
2016-05-27 19:33:09,648 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: queue: default
2016-05-27 19:33:09,651 INFO [main] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Upper limit on the thread pool size is 500
2016-05-27 19:33:09,653 INFO [main] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2016-05-27 19:33:09,658 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1464147437282_0417Job Transitioned from INITED to SETUP
2016-05-27 19:33:09,659 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_SETUP
2016-05-27 19:33:09,666 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1464147437282_0417Job Transitioned from SETUP to RUNNING
2016-05-27 19:33:09,681 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1464147437282_0417_m_000000 Task Transitioned from NEW to SCHEDULED
2016-05-27 19:33:09,681 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1464147437282_0417_m_000001 Task Transitioned from NEW to SCHEDULED
2016-05-27 19:33:09,682 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1464147437282_0417_m_000002 Task Transitioned from NEW to SCHEDULED
2016-05-27 19:33:09,682 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1464147437282_0417_m_000003 Task Transitioned from NEW to SCHEDULED
2016-05-27 19:33:09,683 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000000_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2016-05-27 19:33:09,683 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000001_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2016-05-27 19:33:09,683 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000002_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2016-05-27 19:33:09,683 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000003_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2016-05-27 19:33:09,684 INFO [Thread-50] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: mapResourceRequest:<memory:1024, vCores:1>
2016-05-27 19:33:09,735 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Event Writer setup for JobId: job_1464147437282_0417, File: hdfs://parcom01.cs.du.edu:54410/tmp/hadoop-yarn/staging/maximkolb/.staging/job_1464147437282_0417/job_1464147437282_0417_1.jhist
2016-05-27 19:33:10,653 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:4 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:0 ContRel:0 HostLocal:0 RackLocal:0
2016-05-27 19:33:10,681 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1464147437282_0417: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:24576, vCores:-4> knownNMs=4
2016-05-27 19:33:11,693 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 4
2016-05-27 19:33:11,694 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved parcom02.cs.du.edu to /default-rack
2016-05-27 19:33:11,695 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved parcom04.cs.du.edu to /default-rack
2016-05-27 19:33:11,695 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved parcom01.cs.du.edu to /default-rack
2016-05-27 19:33:11,695 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved parcom03.cs.du.edu to /default-rack
2016-05-27 19:33:11,696 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1464147437282_0417_01_000002 to attempt_1464147437282_0417_m_000000_0
2016-05-27 19:33:11,697 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1464147437282_0417_01_000003 to attempt_1464147437282_0417_m_000001_0
2016-05-27 19:33:11,697 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1464147437282_0417_01_000004 to attempt_1464147437282_0417_m_000002_0
2016-05-27 19:33:11,697 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1464147437282_0417_01_000005 to attempt_1464147437282_0417_m_000003_0
2016-05-27 19:33:11,697 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:4 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:4 ContRel:0 HostLocal:0 RackLocal:0
2016-05-27 19:33:11,734 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved parcom02.cs.du.edu to /default-rack
2016-05-27 19:33:11,746 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: The job-jar file on the remote FS is hdfs://parcom01.cs.du.edu:54410/tmp/hadoop-yarn/staging/maximkolb/.staging/job_1464147437282_0417/job.jar
2016-05-27 19:33:11,748 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: The job-conf file on the remote FS is /tmp/hadoop-yarn/staging/maximkolb/.staging/job_1464147437282_0417/job.xml
2016-05-27 19:33:11,753 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Adding #0 tokens and #1 secret keys for NM use for launching container
2016-05-27 19:33:11,753 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Size of containertokens_dob is 1
2016-05-27 19:33:11,753 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Putting shuffle token in serviceData
2016-05-27 19:33:11,781 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000000_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2016-05-27 19:33:11,784 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved parcom04.cs.du.edu to /default-rack
2016-05-27 19:33:11,785 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000001_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2016-05-27 19:33:11,785 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved parcom01.cs.du.edu to /default-rack
2016-05-27 19:33:11,785 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000002_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2016-05-27 19:33:11,785 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved parcom03.cs.du.edu to /default-rack
2016-05-27 19:33:11,786 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000003_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2016-05-27 19:33:11,787 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1464147437282_0417_01_000002 taskAttempt attempt_1464147437282_0417_m_000000_0
2016-05-27 19:33:11,787 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1464147437282_0417_01_000003 taskAttempt attempt_1464147437282_0417_m_000001_0
2016-05-27 19:33:11,788 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1464147437282_0417_01_000004 taskAttempt attempt_1464147437282_0417_m_000002_0
2016-05-27 19:33:11,793 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1464147437282_0417_01_000005 taskAttempt attempt_1464147437282_0417_m_000003_0
2016-05-27 19:33:11,793 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1464147437282_0417_m_000000_0
2016-05-27 19:33:11,793 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1464147437282_0417_m_000001_0
2016-05-27 19:33:11,793 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1464147437282_0417_m_000002_0
2016-05-27 19:33:11,794 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1464147437282_0417_m_000003_0
2016-05-27 19:33:11,794 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : parcom04.cs.du.edu:38802
2016-05-27 19:33:11,811 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : parcom02.cs.du.edu:36606
2016-05-27 19:33:11,812 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : parcom03.cs.du.edu:44763
2016-05-27 19:33:11,815 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : parcom01.cs.du.edu:55247
2016-05-27 19:33:11,856 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1464147437282_0417_m_000003_0 : 13562
2016-05-27 19:33:11,858 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1464147437282_0417_m_000003_0] using containerId: [container_1464147437282_0417_01_000005 on NM: [parcom03.cs.du.edu:44763]
2016-05-27 19:33:11,860 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000003_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2016-05-27 19:33:11,861 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1464147437282_0417_m_000003 Task Transitioned from SCHEDULED to RUNNING
2016-05-27 19:33:11,861 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1464147437282_0417_m_000001_0 : 13562
2016-05-27 19:33:11,861 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1464147437282_0417_m_000001_0] using containerId: [container_1464147437282_0417_01_000003 on NM: [parcom04.cs.du.edu:38802]
2016-05-27 19:33:11,861 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000001_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2016-05-27 19:33:11,861 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1464147437282_0417_m_000001 Task Transitioned from SCHEDULED to RUNNING
2016-05-27 19:33:11,866 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1464147437282_0417_m_000000_0 : 13562
2016-05-27 19:33:11,866 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1464147437282_0417_m_000000_0] using containerId: [container_1464147437282_0417_01_000002 on NM: [parcom02.cs.du.edu:36606]
2016-05-27 19:33:11,866 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000000_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2016-05-27 19:33:11,867 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1464147437282_0417_m_000000 Task Transitioned from SCHEDULED to RUNNING
2016-05-27 19:33:11,870 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1464147437282_0417_m_000002_0 : 13562
2016-05-27 19:33:11,870 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1464147437282_0417_m_000002_0] using containerId: [container_1464147437282_0417_01_000004 on NM: [parcom01.cs.du.edu:55247]
2016-05-27 19:33:11,871 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000002_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2016-05-27 19:33:11,871 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1464147437282_0417_m_000002 Task Transitioned from SCHEDULED to RUNNING
2016-05-27 19:33:12,699 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1464147437282_0417: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:20480, vCores:-8> knownNMs=4
2016-05-27 19:33:13,401 INFO [Socket Reader #1 for port 60124] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1464147437282_0417 (auth:SIMPLE)
2016-05-27 19:33:13,422 INFO [IPC Server handler 0 on 60124] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1464147437282_0417_m_000003 asked for a task
2016-05-27 19:33:13,422 INFO [IPC Server handler 0 on 60124] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1464147437282_0417_m_000003 given task: attempt_1464147437282_0417_m_000001_0
2016-05-27 19:33:13,608 INFO [Socket Reader #1 for port 60124] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1464147437282_0417 (auth:SIMPLE)
2016-05-27 19:33:13,622 INFO [IPC Server handler 0 on 60124] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1464147437282_0417_m_000005 asked for a task
2016-05-27 19:33:13,622 INFO [IPC Server handler 0 on 60124] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1464147437282_0417_m_000005 given task: attempt_1464147437282_0417_m_000003_0
2016-05-27 19:33:13,715 INFO [Socket Reader #1 for port 60124] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1464147437282_0417 (auth:SIMPLE)
2016-05-27 19:33:13,731 INFO [IPC Server handler 1 on 60124] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1464147437282_0417_m_000004 asked for a task
2016-05-27 19:33:13,731 INFO [IPC Server handler 1 on 60124] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1464147437282_0417_m_000004 given task: attempt_1464147437282_0417_m_000002_0
2016-05-27 19:33:15,379 INFO [Socket Reader #1 for port 60124] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1464147437282_0417 (auth:SIMPLE)
2016-05-27 19:33:15,400 INFO [IPC Server handler 2 on 60124] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1464147437282_0417_m_000002 asked for a task
2016-05-27 19:33:15,400 INFO [IPC Server handler 2 on 60124] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1464147437282_0417_m_000002 given task: attempt_1464147437282_0417_m_000000_0
2016-05-27 19:33:20,455 INFO [IPC Server handler 3 on 60124] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1464147437282_0417_m_000001_0 is : 0.0
2016-05-27 19:33:20,693 INFO [IPC Server handler 4 on 60124] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1464147437282_0417_m_000003_0 is : 0.0
2016-05-27 19:33:20,715 INFO [IPC Server handler 3 on 60124] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1464147437282_0417_m_000002_0 is : 0.0
2016-05-27 19:33:22,997 INFO [IPC Server handler 6 on 60124] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1464147437282_0417_m_000000_0 is : 0.0
2016-05-27 19:33:26,771 INFO [IPC Server handler 7 on 60124] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1464147437282_0417_m_000002_0 is : 1.0
2016-05-27 19:33:29,216 INFO [IPC Server handler 5 on 60124] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1464147437282_0417_m_000000_0 is : 1.0
2016-05-27 19:33:29,517 INFO [IPC Server handler 9 on 60124] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1464147437282_0417_m_000001_0 is : 1.0
2016-05-27 19:33:29,864 INFO [IPC Server handler 5 on 60124] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1464147437282_0417_m_000002_0 is : 1.0
2016-05-27 19:33:29,932 INFO [IPC Server handler 9 on 60124] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1464147437282_0417_m_000003_0 is : 1.0
2016-05-27 19:33:33,037 INFO [IPC Server handler 10 on 60124] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1464147437282_0417_m_000003_0 is : 1.0
2016-05-27 19:33:33,422 INFO [IPC Server handler 8 on 60124] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1464147437282_0417_m_000000_0 is : 1.0
2016-05-27 19:33:34,459 INFO [IPC Server handler 11 on 60124] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1464147437282_0417_m_000001_0 is : 1.0
2016-05-27 19:33:35,224 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1464147437282_0417_01_000005
2016-05-27 19:33:35,225 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:3 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:4 ContRel:0 HostLocal:0 RackLocal:0
2016-05-27 19:33:35,225 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000003_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2016-05-27 19:33:35,225 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1464147437282_0417_m_000003_0: Exception from container-launch.
Container id: container_1464147437282_0417_01_000005
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:538)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:715)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)


Container exited with a non-zero exit code 1

2016-05-27 19:33:35,226 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1464147437282_0417_01_000005 taskAttempt attempt_1464147437282_0417_m_000003_0
2016-05-27 19:33:35,226 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1464147437282_0417_m_000003_0
2016-05-27 19:33:35,226 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : parcom03.cs.du.edu:44763
2016-05-27 19:33:35,244 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000003_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2016-05-27 19:33:35,244 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2016-05-27 19:33:35,258 WARN [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://parcom01.cs.du.edu:54410/u/home/maximkolb/Comp3705Processing/svn/Program4/Job2Output/_temporary/1/_temporary/attempt_1464147437282_0417_m_000003_0
2016-05-27 19:33:35,260 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000003_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2016-05-27 19:33:35,267 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1464147437282_0417_m_000003 Task Transitioned from RUNNING to FAILED
2016-05-27 19:33:35,267 INFO [Thread-50] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 1 failures on node parcom03.cs.du.edu
2016-05-27 19:33:35,269 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 1
2016-05-27 19:33:35,269 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Job failed as tasks failed. failedMaps:1 failedReduces:0
2016-05-27 19:33:35,270 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1464147437282_0417Job Transitioned from RUNNING to FAIL_WAIT
2016-05-27 19:33:35,272 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1464147437282_0417_m_000000 Task Transitioned from RUNNING to KILL_WAIT
2016-05-27 19:33:35,272 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1464147437282_0417_m_000001 Task Transitioned from RUNNING to KILL_WAIT
2016-05-27 19:33:35,272 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1464147437282_0417_m_000002 Task Transitioned from RUNNING to KILL_WAIT
2016-05-27 19:33:35,272 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000000_0 TaskAttempt Transitioned from RUNNING to KILL_CONTAINER_CLEANUP
2016-05-27 19:33:35,272 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000001_0 TaskAttempt Transitioned from RUNNING to KILL_CONTAINER_CLEANUP
2016-05-27 19:33:35,272 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000002_0 TaskAttempt Transitioned from RUNNING to KILL_CONTAINER_CLEANUP
2016-05-27 19:33:35,273 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1464147437282_0417_01_000002 taskAttempt attempt_1464147437282_0417_m_000000_0
2016-05-27 19:33:35,273 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1464147437282_0417_01_000003 taskAttempt attempt_1464147437282_0417_m_000001_0
2016-05-27 19:33:35,274 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1464147437282_0417_m_000001_0
2016-05-27 19:33:35,274 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : parcom04.cs.du.edu:38802
2016-05-27 19:33:35,274 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1464147437282_0417_01_000004 taskAttempt attempt_1464147437282_0417_m_000002_0
2016-05-27 19:33:35,274 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1464147437282_0417_m_000002_0
2016-05-27 19:33:35,274 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : parcom01.cs.du.edu:55247
2016-05-27 19:33:35,275 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1464147437282_0417_m_000000_0
2016-05-27 19:33:35,277 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : parcom02.cs.du.edu:36606
2016-05-27 19:33:35,289 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000001_0 TaskAttempt Transitioned from KILL_CONTAINER_CLEANUP to KILL_TASK_CLEANUP
2016-05-27 19:33:35,290 INFO [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2016-05-27 19:33:35,292 WARN [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://parcom01.cs.du.edu:54410/u/home/maximkolb/Comp3705Processing/svn/Program4/Job2Output/_temporary/1/_temporary/attempt_1464147437282_0417_m_000001_0
2016-05-27 19:33:35,293 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000001_0 TaskAttempt Transitioned from KILL_TASK_CLEANUP to KILLED
2016-05-27 19:33:35,293 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1464147437282_0417_m_000001 Task Transitioned from KILL_WAIT to KILLED
2016-05-27 19:33:35,301 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000002_0 TaskAttempt Transitioned from KILL_CONTAINER_CLEANUP to KILL_TASK_CLEANUP
2016-05-27 19:33:35,305 INFO [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2016-05-27 19:33:35,308 WARN [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://parcom01.cs.du.edu:54410/u/home/maximkolb/Comp3705Processing/svn/Program4/Job2Output/_temporary/1/_temporary/attempt_1464147437282_0417_m_000002_0
2016-05-27 19:33:35,308 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000002_0 TaskAttempt Transitioned from KILL_TASK_CLEANUP to KILLED
2016-05-27 19:33:35,308 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1464147437282_0417_m_000002 Task Transitioned from KILL_WAIT to KILLED
2016-05-27 19:33:35,311 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000000_0 TaskAttempt Transitioned from KILL_CONTAINER_CLEANUP to KILL_TASK_CLEANUP
2016-05-27 19:33:35,311 INFO [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2016-05-27 19:33:35,558 WARN [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://parcom01.cs.du.edu:54410/u/home/maximkolb/Comp3705Processing/svn/Program4/Job2Output/_temporary/1/_temporary/attempt_1464147437282_0417_m_000000_0
2016-05-27 19:33:35,559 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1464147437282_0417_m_000000_0 TaskAttempt Transitioned from KILL_TASK_CLEANUP to KILLED
2016-05-27 19:33:35,559 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1464147437282_0417_m_000000 Task Transitioned from KILL_WAIT to KILLED
2016-05-27 19:33:35,560 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1464147437282_0417Job Transitioned from FAIL_WAIT to FAIL_ABORT
2016-05-27 19:33:35,560 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_ABORT
2016-05-27 19:33:35,565 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1464147437282_0417Job Transitioned from FAIL_ABORT to FAILED
2016-05-27 19:33:35,566 INFO [Thread-69] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: We are finishing cleanly so this is the last retry
2016-05-27 19:33:35,566 INFO [Thread-69] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify RMCommunicator isAMLastRetry: true
2016-05-27 19:33:35,566 INFO [Thread-69] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: RMCommunicator notified that shouldUnregistered is: true
2016-05-27 19:33:35,566 INFO [Thread-69] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify JHEH isAMLastRetry: true
2016-05-27 19:33:35,566 INFO [Thread-69] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: JobHistoryEventHandler notified that forceJobCompletion is true
2016-05-27 19:33:35,566 INFO [Thread-69] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Calling stop for all the services
2016-05-27 19:33:35,566 INFO [Thread-69] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler. Size of the outstanding queue size is 0
2016-05-27 19:33:35,596 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://parcom01.cs.du.edu:54410/tmp/hadoop-yarn/staging/maximkolb/.staging/job_1464147437282_0417/job_1464147437282_0417_1.jhist to hdfs://parcom01.cs.du.edu:54410/tmp/hadoop-yarn/staging/history/done_intermediate/maximkolb/job_1464147437282_0417-1464399185155-maximkolb-Giraph%3A+AllShortestPaths-1464399215269-0-0-FAILED-default-1464399189654.jhist_tmp
2016-05-27 19:33:35,615 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://parcom01.cs.du.edu:54410/tmp/hadoop-yarn/staging/history/done_intermediate/maximkolb/job_1464147437282_0417-1464399185155-maximkolb-Giraph%3A+AllShortestPaths-1464399215269-0-0-FAILED-default-1464399189654.jhist_tmp
2016-05-27 19:33:35,617 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://parcom01.cs.du.edu:54410/tmp/hadoop-yarn/staging/maximkolb/.staging/job_1464147437282_0417/job_1464147437282_0417_1_conf.xml to hdfs://parcom01.cs.du.edu:54410/tmp/hadoop-yarn/staging/history/done_intermediate/maximkolb/job_1464147437282_0417_conf.xml_tmp
2016-05-27 19:33:35,636 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://parcom01.cs.du.edu:54410/tmp/hadoop-yarn/staging/history/done_intermediate/maximkolb/job_1464147437282_0417_conf.xml_tmp
2016-05-27 19:33:35,641 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://parcom01.cs.du.edu:54410/tmp/hadoop-yarn/staging/history/done_intermediate/maximkolb/job_1464147437282_0417.summary_tmp to hdfs://parcom01.cs.du.edu:54410/tmp/hadoop-yarn/staging/history/done_intermediate/maximkolb/job_1464147437282_0417.summary
2016-05-27 19:33:35,643 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://parcom01.cs.du.edu:54410/tmp/hadoop-yarn/staging/history/done_intermediate/maximkolb/job_1464147437282_0417_conf.xml_tmp to hdfs://parcom01.cs.du.edu:54410/tmp/hadoop-yarn/staging/history/done_intermediate/maximkolb/job_1464147437282_0417_conf.xml
2016-05-27 19:33:35,644 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://parcom01.cs.du.edu:54410/tmp/hadoop-yarn/staging/history/done_intermediate/maximkolb/job_1464147437282_0417-1464399185155-maximkolb-Giraph%3A+AllShortestPaths-1464399215269-0-0-FAILED-default-1464399189654.jhist_tmp to hdfs://parcom01.cs.du.edu:54410/tmp/hadoop-yarn/staging/history/done_intermediate/maximkolb/job_1464147437282_0417-1464399185155-maximkolb-Giraph%3A+AllShortestPaths-1464399215269-0-0-FAILED-default-1464399189654.jhist
2016-05-27 19:33:35,644 INFO [Thread-69] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopped JobHistoryEventHandler. super.stop()
2016-05-27 19:33:35,646 INFO [Thread-69] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Setting job diagnostics to Task failed task_1464147437282_0417_m_000003
Job failed as tasks failed. failedMaps:1 failedReduces:0

2016-05-27 19:33:35,646 INFO [Thread-69] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: History url is http://parcom04.cs.du.edu:19888/jobhistory/job/job_1464147437282_0417
2016-05-27 19:33:35,651 INFO [Thread-69] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Waiting for application to be successfully unregistered.
2016-05-27 19:33:36,653 INFO [Thread-69] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:3 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:4 ContRel:0 HostLocal:0 RackLocal:0
2016-05-27 19:33:36,653 INFO [Thread-69] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Deleting staging directory hdfs://parcom01.cs.du.edu:54410 /tmp/hadoop-yarn/staging/maximkolb/.staging/job_1464147437282_0417
2016-05-27 19:33:36,656 INFO [Thread-69] org.apache.hadoop.ipc.Server: Stopping server on 60124
2016-05-27 19:33:36,658 INFO [IPC Server listener on 60124] org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 60124
2016-05-27 19:33:36,660 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2016-05-27 19:33:36,660 INFO [TaskHeartbeatHandler PingChecker] org.apache.hadoop.mapreduce.v2.app.TaskHeartbeatHandler: TaskHeartbeatHandler thread interrupted

